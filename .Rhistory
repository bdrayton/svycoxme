parts <- make_parts(fit, my_samp)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
my_vcov  = sandwich[1:2, 1:2],
coxme_vcov = vcov(fit),
coefs = coef(fit))
}
try_one_rep <- function(...){
stream <- .Random.seed
r <- try(one_rep(...))
attr(r, "stream") <- stream
r
}
try_one_rep()
debugonce(one_rep)
try_one_rep()
summary(fit)
vcov(fit)
diag(vcov(fit))
sqrt(diag(vcov(fit)))
diag(sandwich)[1:2]
sqrt(diag(sandwich)[1:2])
summary(svycoxph(survival::Surv(stat_time, stat)~X1 + X2, des = my_des))
try_one_rep()
one_rep <- function(specs = list(n_clusters = 25000,
n_clusters_in_samp = 50)){
# one cluster sample
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$weights <- (specs$n_clusters_in_samp/specs$n_clusters)^-1
# could fit with svycoxph, but would be identical
fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + (1|id), data = my_samp, weights = weights)
parts <- make_parts(fit, my_samp)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
my_vcov  = sandwich[1:2, 1:2],
coefs = coef(fit))
}
try_one_rep <- function(...){
stream <- .Random.seed
r <- try(one_rep(...))
attr(r, "stream") <- stream
r
}
try_one_rep()
param_combos <- expand.grid(n_clusters = length(unique(pop$id)),
n_clusters_in_samp = 50)
nsims = 1600
param_combos
# repeat each combination of parameters nsims times
param_combos_nsims <- param_combos[rep(seq_len(nrow(param_combos)), nsims),]
param_combos_list <- split(param_combos_nsims, f = seq_len(nrow(param_combos_nsims)))
# this should be nrow(param_combos) * nsims
nrow(param_combos_nsims)
# test
# debugonce(one_rep)
(r1 <- try_one_rep(param_combos_list[[1]]))
cl <- parallel::makeCluster(parallel::detectCores()-1)
# put objects in place that might be needed for the code
parallel::clusterExport(cl, c("pop", "one_rep"))
# Set a different seed on each member of the cluster (just in case)
parallel::clusterSetRNGStream(cl, iseed = 3528942)
parallel::clusterEvalQ(cl, {
# devtools::load_all(path = "/home/bdra011/svycoxme")
devtools::load_all("C:/Users/bdra011/OneDrive - The University of Auckland/Documents/PhD_local/svycoxme")
# devtools::load_all("C:/Users/Bradley/Documents/PhD_local/svycoxme")
})
fits <- parallel::parLapply(cl, param_combos_list, one_rep)
#stop the cluster
parallel::stopCluster(cl)
is.error <- sapply(fits, inherits, "try-error")
# none
table(is.error)
cl <- parallel::makeCluster(parallel::detectCores()-1)
# put objects in place that might be needed for the code
parallel::clusterExport(cl, c("pop", "one_rep"))
# Set a different seed on each member of the cluster (just in case)
parallel::clusterSetRNGStream(cl, iseed = 3528942)
parallel::clusterEvalQ(cl, {
# devtools::load_all(path = "/home/bdra011/svycoxme")
devtools::load_all("C:/Users/bdra011/OneDrive - The University of Auckland/Documents/PhD_local/svycoxme")
# devtools::load_all("C:/Users/Bradley/Documents/PhD_local/svycoxme")
})
fits <- parallel::parLapply(cl, param_combos_list, try_one_rep)
#stop the cluster
parallel::stopCluster(cl)
head(fits)
is.error <- sapply(fits, inherits, "try-error")
# none
table(is.error)
dnorm(0.95)
dnorm(0.05)
qnorm(0.95)
qnorm(0.975)
qnorm(c(0.025, 0.975))
qnorm(0.025)
shape_res <- function(one_fit){
covars <- names(one_fit$coefs)
v1 <- diag(one_fit$my_vcov)
data.frame(
covariate = covars,
coefs = one_fit$coefs,
variance = v1,
lower = one_fit$coefs + qnorm(0.025) * sqrt(v1),
upper = one_fit$coefs + qnorm(0.975) * sqrt(v1)
)
}
shape_res(fits[[1]])
fits_df <- lapply(fits[!is.error], shape_res)
df <- Reduce(rbind.data.frame, fits_df)
library(tidyverse)
df %>%
ggplot(aes(sqrt(variance))) +
facet_grid(rows = vars(covariate), scales = 'free') +
geom_density()
bias <- function(theta, true_theta){
sum(theta - true_theta)/length(theta)
}
# identical, obviously, since it's the same coef.
df %>%
group_by(covariate) %>%
summarise(bias = bias(coefs, true_theta = 1))
EmpSE <- function(theta){
theta_bar = mean(theta)
sqrt( sum((theta-mean(theta))^2)/(length(theta)-1) )
}
df %>%
group_by(covariate) %>%
summarise(bias = bias(coefs, true_theta = 1),
EmpSE = EmpSE(coefs),
MeanSE = mean(sqrt(variance)),
diff = EmpSE - MeanSE)
names(df)
df %>%
group_by(covariate) %>%
mutate(hit = lower < 1 & upper > 1) %>%
summarise(mean(hit))
df %>%
arrange(lower) %>%
group_by(covariate) %>%
mutate(hit = lower < 1 & upper > 1,
index = row_number()) %>%
ggplot(aes(index, xmin = lower, xmax = upper, colour = hit)) +
geom_errorbarh(height = 0) +
facet_grid(rows = vars(covariate))
df %>%
arrange(lower) %>%
group_by(covariate) %>%
mutate(hit = lower < 1 & upper > 1,
index = row_number()) %>%
ggplot(aes(y = index, xmin = lower, xmax = upper, colour = hit)) +
geom_errorbarh(height = 0) +
facet_grid(rows = vars(covariate))
df %>%
arrange(lower) %>%
group_by(covariate) %>%
mutate(hit = lower < 1 & upper > 1,
index = row_number()) %>%
ggplot(aes(y = index, xmin = lower, xmax = upper, colour = hit)) +
geom_errorbarh(height = 0) +
facet_grid(rows = vars(covariate)) +
geom_vline(xintercept = 1)
# remove bias
df %>%
arrange(lower) %>%
group_by(covariate) %>%
mutate(hit = lower-0.1 < 1 & upper-0.1 > 1,
index = row_number()) %>%
ggplot(aes(y = index, xmin = lower, xmax = upper, colour = hit)) +
geom_errorbarh(height = 0) +
facet_grid(rows = vars(covariate)) +
geom_vline(xintercept = 1)
# remove bias
df %>%
arrange(lower) %>%
group_by(covariate) %>%
mutate(hit = lower-0.1 < 1 & upper-0.1 > 1,
index = row_number()) %>%
ggplot(aes(y = index, xmin = lower-0.1, xmax = upper-0.1, colour = hit)) +
geom_errorbarh(height = 0) +
facet_grid(rows = vars(covariate)) +
geom_vline(xintercept = 1)
df %>%
group_by(covariate) %>%
mutate(hit = (lower - 0.1) < 1 & (upper = 0.1) > 1) %>%
summarise(mean(hit))
df %>%
group_by(covariate) %>%
mutate(hit = (lower - 0.1) < 1 & (upper - 0.1) > 1) %>%
summarise(mean(hit))
survey:::svycoxph.survey.design
one_rep <- function(specs = list(n_clusters = 25000,
n_clusters_in_samp = 50)){
# one cluster sample
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + (1|id), data = my_samp, weights = rweights)
parts <- make_parts(fit, my_samp)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
my_vcov  = sandwich[1:2, 1:2],
coefs = coef(fit))
}
try_one_rep <- function(...){
stream <- .Random.seed
r <- try(one_rep(...))
attr(r, "stream") <- stream
r
}
try_one_rep()
debugonce(one_rep)
try_one_rep()
debugonce(one_rep)
try_one_rep()
debugonce(make_parts.coxme)
try_one_rep()
form
call(coxme.object)
coxme.object$call
weights(coxfit_weighted)
my_samp$rweight <- my_samp$weight/mean(my_samp$weight)
coxfit_weighted <- coxme::coxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), data = my_samp, weights = rweight)
weights(coxfit_weighted)
my_samp$rweight
my_samp$weight <- my_samp$weight/mean(my_samp$weight)
coxfit_weighted <- coxme::coxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), data = my_samp, weights = weight)
weights(coxfit_weighted)
devtools::load_all(".")
one_rep <- function(specs = list(n_clusters = 25000,
n_clusters_in_samp = 50)){
# one cluster sample
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + (1|id), data = my_samp, weights = rweights)
parts <- make_parts(fit, my_samp)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
my_vcov  = sandwich[1:2, 1:2],
coefs = coef(fit))
}
try_one_rep <- function(...){
stream <- .Random.seed
r <- try(one_rep(...))
attr(r, "stream") <- stream
r
}
debugonce(one_rep)
try_one_rep()
try_one_rep()
debugonce(one_rep)
try_one_rep()
diag(vcov(fit))
diag(sandwich[1:2, 1:2])
one_rep <- function(specs = list(n_clusters = 25000,
n_clusters_in_samp = 50)){
# one cluster sample
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + (1|id), data = my_samp, weights = rweights)
parts <- make_parts(fit, my_samp)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
my_vcov  = sandwich[1:2, 1:2],
coxme_vcov = vcov(fit),
coefs = coef(fit))
}
try_one_rep <- function(...){
stream <- .Random.seed
r <- try(one_rep(...))
attr(r, "stream") <- stream
r
}
try_one_rep()
param_combos <- expand.grid(n_clusters = length(unique(pop$id)),
n_clusters_in_samp = 50)
nsims = 160
# repeat each combination of parameters nsims times
param_combos_nsims <- param_combos[rep(seq_len(nrow(param_combos)), nsims),]
param_combos_list <- split(param_combos_nsims, f = seq_len(nrow(param_combos_nsims)))
# this should be nrow(param_combos) * nsims
nrow(param_combos_nsims)
# test
# debugonce(one_rep)
(r1 <- try_one_rep(param_combos_list[[1]]))
cl <- parallel::makeCluster(parallel::detectCores()-1)
# put objects in place that might be needed for the code
parallel::clusterExport(cl, c("pop", "one_rep"))
# Set a different seed on each member of the cluster (just in case)
# this could be set to avoid errors. currently one error.
parallel::clusterSetRNGStream(cl, iseed = 3528942)
parallel::clusterEvalQ(cl, {
# devtools::load_all(path = "/home/bdra011/svycoxme")
devtools::load_all("C:/Users/bdra011/OneDrive - The University of Auckland/Documents/PhD_local/svycoxme")
# devtools::load_all("C:/Users/Bradley/Documents/PhD_local/svycoxme")
})
fits <- parallel::parLapply(cl, param_combos_list, try_one_rep)
#stop the cluster
parallel::stopCluster(cl)
head(fits)
is.error <- sapply(fits, inherits, "try-error")
# none
table(is.error)
shape_res <- function(one_fit){
covars <- names(one_fit$coefs)
v1 <- diag(one_fit$my_vcov)
v2 <- diag(one_fit$coxme_vcov)
data.frame(
covariate = rep(covars, 2),
coefs = rep(one_fit$coefs, 2),
variance = v1,
lower = one_fit$coefs + qnorm(0.025) * sqrt(c(v1, v2)),
upper = one_fit$coefs + qnorm(0.975) * sqrt(c(v1, v2))
)
}
shape_res(fits[[1]])
fits_df <- lapply(fits[!is.error], shape_res)
df <- Reduce(rbind.data.frame, fits_df)
library(tidyverse)
shape_res <- function(one_fit){
covars <- names(one_fit$coefs)
v1 <- diag(one_fit$my_vcov)
v2 <- diag(one_fit$coxme_vcov)
data.frame(
method = rep(c("sandwich", "mle"), each = 2),
covariate = rep(covars, 2),
coefs = rep(one_fit$coefs, 2),
variance = v1,
lower = one_fit$coefs + qnorm(0.025) * sqrt(c(v1, v2)),
upper = one_fit$coefs + qnorm(0.975) * sqrt(c(v1, v2))
)
}
shape_res(fits[[1]])
fits_df <- lapply(fits[!is.error], shape_res)
df <- Reduce(rbind.data.frame, fits_df)
df %>%
ggplot(aes(sqrt(variance))) +
facet_grid(rows = vars(covariate, method), scales = 'free') +
geom_density()
bias <- function(theta, true_theta){
sum(theta - true_theta)/length(theta)
}
df %>%
group_by(covariate) %>%
summarise(bias = bias(coefs, true_theta = 1))
df %>%
group_by(covariate, method) %>%
summarise(bias = bias(coefs, true_theta = 1))
EmpSE <- function(theta){
theta_bar = mean(theta)
sqrt( sum((theta-mean(theta))^2)/(length(theta)-1) )
}
df %>%
group_by(method, covariate) %>%
summarise(bias = bias(coefs, true_theta = 1),
EmpSE = EmpSE(coefs),
MeanSE = mean(sqrt(variance)),
diff = EmpSE - MeanSE)
df %>%
group_by(method, covariate) %>%
mutate(hit = lower < 1 & upper > 1) %>%
summarise(mean(hit))
# if estimated bias is removed
# much better. how to improve bias? the weights need to be scaled I recon.
df %>%
group_by(covariate) %>%
mutate(hit = (lower + 0.02) < 1 & (upper + 0.02) > 1) %>%
summarise(mean(hit))
# if estimated bias is removed
# much better. how to improve bias? the weights need to be scaled I recon.
df %>%
group_by(covariate, method) %>%
mutate(hit = (lower + 0.02) < 1 & (upper + 0.02) > 1) %>%
summarise(mean(hit))
nsims = 1600
# repeat each combination of parameters nsims times
param_combos_nsims <- param_combos[rep(seq_len(nrow(param_combos)), nsims),]
param_combos_list <- split(param_combos_nsims, f = seq_len(nrow(param_combos_nsims)))
# this should be nrow(param_combos) * nsims
nrow(param_combos_nsims)
# test
# debugonce(one_rep)
(r1 <- try_one_rep(param_combos_list[[1]]))
cl <- parallel::makeCluster(parallel::detectCores()-1)
# put objects in place that might be needed for the code
parallel::clusterExport(cl, c("pop", "one_rep"))
# Set a different seed on each member of the cluster (just in case)
# this could be set to avoid errors. currently one error.
parallel::clusterSetRNGStream(cl, iseed = 3528942)
parallel::clusterEvalQ(cl, {
# devtools::load_all(path = "/home/bdra011/svycoxme")
devtools::load_all("C:/Users/bdra011/OneDrive - The University of Auckland/Documents/PhD_local/svycoxme")
# devtools::load_all("C:/Users/Bradley/Documents/PhD_local/svycoxme")
})
fits <- parallel::parLapply(cl, param_combos_list, try_one_rep)
#stop the cluster
parallel::stopCluster(cl)
is.error <- sapply(fits, inherits, "try-error")
# none
table(is.error)
shape_res <- function(one_fit){
covars <- names(one_fit$coefs)
v1 <- diag(one_fit$my_vcov)
v2 <- diag(one_fit$coxme_vcov)
data.frame(
method = rep(c("sandwich", "mle"), each = 2),
covariate = rep(covars, 2),
coefs = rep(one_fit$coefs, 2),
variance = v1,
lower = one_fit$coefs + qnorm(0.025) * sqrt(c(v1, v2)),
upper = one_fit$coefs + qnorm(0.975) * sqrt(c(v1, v2))
)
}
shape_res(fits[[1]])
fits_df <- lapply(fits[!is.error], shape_res)
df <- Reduce(rbind.data.frame, fits_df)
library(tidyverse)
df %>%
ggplot(aes(sqrt(variance))) +
facet_grid(rows = vars(covariate, method), scales = 'free') +
geom_density()
bias <- function(theta, true_theta){
sum(theta - true_theta)/length(theta)
}
df %>%
group_by(covariate, method) %>%
summarise(bias = bias(coefs, true_theta = 1))
EmpSE <- function(theta){
theta_bar = mean(theta)
sqrt( sum((theta-mean(theta))^2)/(length(theta)-1) )
}
df %>%
group_by(method, covariate) %>%
summarise(bias = bias(coefs, true_theta = 1),
EmpSE = EmpSE(coefs),
MeanSE = mean(sqrt(variance)),
diff = EmpSE - MeanSE)
df %>%
group_by(method, covariate) %>%
mutate(hit = lower < 1 & upper > 1) %>%
summarise(mean(hit))
