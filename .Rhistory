<<<<<<< Updated upstream
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
my_samp <- my_samp[order(my_samp$stat_time), ]
# the regular fit.
coxme_fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + (1|id), data = my_samp, weights = rweights)
# calculate ui and Hessian
parts <- make_parts(coxme_fit, my_samp, weights = my_samp$weights)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
my_des_rep <- as.svrepdesign(my_des)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
svycoxme_fit <- svycoxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), des = sv)
# calculate sandwich variance
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
sandwich_var  = diag(sandwich)[1:2],
svycoxme_var = diag(vcov(svycoxme_fit)),
coefs = coef(svycoxme_fit))
}
try_one_rep <- function(...){
stream <- .Random.seed
r <- try(one_rep(...))
attr(r, "stream") <- stream
r
}
# set to 20 for Ihaka
cores <- 5
# set to 20 for Ihaka
cores <- 5
cl <- parallel::makeCluster(cores)
# put objects in place that might be needed for the code
parallel::clusterExport(cl, c("one_rep", "try_one_rep", "svycoxme_path"))
# Set a different seed on each member of the cluster (just in case)
# this could be set to avoid errors. currently one error.
parallel::clusterSetRNGStream(cl, iseed = 3528942)
parallel::clusterEvalQ(cl, {
# devtools::load_all(path = "/home/bdra011/svycoxme")
devtools::load_all(svycoxme_path)
# devtools::load_all("C:/Users/Bradley/Documents/PhD_local/svycoxme")
})
run_one_pop <- function(theta){
# Build pop
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + X2 + (1 | M1),
dists = list(X1 = ~rnorm(n),
X2 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(X1 = 1, X2 = 1),
random_effect_variance = list(M1 = theta)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
parallel::clusterExport(cl, c("pop"), envir = environment())
fits <- parallel::parLapply(cl, param_combos_list, try_one_rep)
fits
}
test_fits <- run_one_pop(1)
test_fits
# define one rep
one_rep <- function(specs){
# one cluster sample
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
my_samp <- my_samp[order(my_samp$stat_time), ]
# the regular fit.
coxme_fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + (1|id), data = my_samp, weights = rweights)
# calculate ui and Hessian
parts <- make_parts(coxme_fit, my_samp, weights = my_samp$weights)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
my_des_rep <- as.svrepdesign(my_des)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
svycoxme_fit <- svycoxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), des = my_des_rep)
# calculate sandwich variance
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
sandwich_var  = diag(sandwich)[1:2],
svycoxme_var = diag(vcov(svycoxme_fit)),
coefs = coef(svycoxme_fit))
}
test_fits <- run_one_pop(1)
table(sapply(test_fits, inherits, "try-error"))
test_fits[[1]]
# define one rep
one_rep <- function(specs){
# one cluster sample
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
my_samp <- my_samp[order(my_samp$stat_time), ]
# the regular fit.
coxme_fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + (1|id), data = my_samp, weights = rweights)
# calculate ui and Hessian
parts <- make_parts(coxme_fit, my_samp, weights = my_samp$weights)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
my_des_rep <- as.svrepdesign(my_des)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
svycoxme_fit <- svycoxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), des = my_des_rep)
# calculate sandwich variance
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
sandwich_var  = diag(sandwich)[1:2],
svycoxme_var = diag(vcov(svycoxme_fit)),
coefs = coef(svycoxme_fit))
}
try_one_rep <- function(...){
stream <- .Random.seed
r <- try(one_rep(...))
attr(r, "stream") <- stream
r
}
# put objects in place that might be needed for the code
parallel::clusterExport(cl, c("one_rep", "try_one_rep", "svycoxme_path"))
run_one_pop <- function(theta){
# Build pop
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + X2 + (1 | M1),
dists = list(X1 = ~rnorm(n),
X2 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(X1 = 1, X2 = 1),
random_effect_variance = list(M1 = theta)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
parallel::clusterExport(cl, c("pop"), envir = environment())
fits <- parallel::parLapply(cl, param_combos_list, try_one_rep)
fits
}
test_fits <- run_one_pop(1)
table(sapply(test_fits, inherits, "try-error"))
test_fits
all_fits <- lapply(thetas, run_one_pop)
#stop the cluster
parallel::stopCluster(cl)
is.error <- sapply(fits, inherits, "try-error")
is.error <- sapply(all_fits, inherits, "try-error")
# none
table(is.error)
all_fits_unlist <- unlist(all_fits, recursive = FALSE)
is.error <- sapply(all_fits_unlist, inherits, "try-error")
# none
table(is.error)
all_fits_unlist <- unlist(all_fits, recursive = FALSE)
is.error <- sapply(all_fits_unlist, inherits, "try-error")
# none
table(is.error)
names(all_fits_unlist[[1]])
shape_res <- function(one_fit){
covars <- names(one_fit$coefs)
v1 <- diag(one_fit$sandwich_var)
v2 <- diag(one_fit$svycoxme_var)
data.frame(
method = rep(c("sandwich", "bootstrap"), each = 2),
covariate = rep(covars, 2),
coefs = rep(one_fit$coefs, 2),
variance = c(v1, v2),
lower = one_fit$coefs + qnorm(0.025) * sqrt(c(v1, v2)),
upper = one_fit$coefs + qnorm(0.975) * sqrt(c(v1, v2))
)
}
shape_res(fits[[1]])
shape_res(all_fits_unlist[[1]])
shape_res <- function(one_fit){
covars <- names(one_fit$coefs)
v1 <- one_fit$sandwich_var
v2 <- one_fit$svycoxme_var
data.frame(
method = rep(c("sandwich", "bootstrap"), each = 2),
covariate = rep(covars, 2),
coefs = rep(one_fit$coefs, 2),
variance = c(v1, v2),
lower = one_fit$coefs + qnorm(0.025) * sqrt(c(v1, v2)),
upper = one_fit$coefs + qnorm(0.975) * sqrt(c(v1, v2))
)
}
shape_res(all_fits_unlist[[1]])
fits_df <- lapply(fits[!is.error], shape_res)
fits_df <- lapply(all_fits_unlist[!is.error], shape_res)
df <- Reduce(rbind.data.frame, fits_df)
library(tidyverse)
df %>%
ggplot(aes(sqrt(variance))) +
facet_grid(rows = vars(covariate, method), scales = 'free') +
geom_density()
bias <- function(theta, true_theta){
sum(theta - true_theta)/length(theta)
}
df %>%
group_by(covariate, method) %>%
summarise(bias = bias(coefs, true_theta = 1))
EmpSE <- function(theta){
theta_bar = mean(theta)
sqrt( sum((theta-mean(theta))^2)/(length(theta)-1) )
}
df %>%
group_by(method, covariate) %>%
summarise(bias = bias(coefs, true_theta = 1),
EmpSE = EmpSE(coefs),
MeanSE = mean(sqrt(variance)),
diff = EmpSE - MeanSE)
# number of 'hits'
# about the same coverage. Will need to check for a range of parameters and sampling situations.
df %>%
group_by(method, covariate) %>%
mutate(hit = lower < 1 & upper > 1) %>%
summarise(mean(hit))
df %>%
arrange(lower) %>%
group_by(covariate) %>%
mutate(hit = lower < 1 & upper > 1,
index = row_number()) %>%
ggplot(aes(y = index, xmin = lower, xmax = upper, colour = hit)) +
geom_errorbarh(height = 0) +
facet_grid(rows = vars(covariate)) +
geom_vline(xintercept = 1)
devtools::load_all(".")
devtools::load_all(".")
Sys.info()
Sys.getenv()
svycoxme::svycoxme
devtools::load_all(".")
svycoxme::svycoxme
svycoxme
svycoxme.svyrep.design
devtools::load_all(".")
cluster_str <- data.frame(table(Size = rpois(2500, 2) + 6)) |>
dplyr::filter(Freq >=10)
cluster_str_list <- split(cluster_str, seq(nrow(cluster_str)))
max_cluster_digits <- max(nchar(as.character(cluster_str$Size)))
max_cluster_freq_digits <- max(nchar(as.character(cluster_str$Freq)))
set.seed(949742)
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + (1 | M1),
dists = list(X1 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(1),
random_effect_variance = list(M1 = 0)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
devtools::load_all(".")
cluster_str <- data.frame(table(Size = rpois(2500, 2) + 6)) |>
dplyr::filter(Freq >=10)
cluster_str_list <- split(cluster_str, seq(nrow(cluster_str)))
max_cluster_digits <- max(nchar(as.character(cluster_str$Size)))
max_cluster_freq_digits <- max(nchar(as.character(cluster_str$Freq)))
set.seed(949742)
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + (1 | M1),
dists = list(X1 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(1),
random_effect_variance = list(M1 = 0)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
# simple random sample
my_samp <- pop[sample.int(nrow(pop), 500),]
# sort samp by time.
my_samp <- my_samp[order(my_samp$stat_time),]
my_samp$weight = 1
N_hat <- sum(my_samp$weight)
BB <- function(formula, weight = NULL, data, beta){
model_frame <- model.frame(formula, data = data)
# first column (response) is actually a (masked) matrix with time and status.
response <- as.matrix(model_frame[ ,1])
time <- response[,"time"]
stat <- response[,"status"]
# sort data by time
time_order <- order(time)
time <- time[time_order]
stat <- stat[time_order]
weight <- weight[time_order]
model_frame <- model_frame[time_order, ]
model_matrix <- model.matrix(formula, data = model_frame)
# calculate the weighted risk sets.
# get X terms
X <- model_matrix[,-1, drop = FALSE]
# this should fail if beta and X don't match dimensions
# I need these to be Matrix::Matrix
risk_score <- Matrix::Matrix(X %*% beta)
# weighted.
exp_risk_score <- weight * exp(risk_score)
rev_exp_risk_score <- exp_risk_score
rev_exp_risk_score@x <- rev(exp_risk_score@x)
# this is S0_hat in binder
at_risk <- Matrix::Matrix(rev(cumsum(rev_exp_risk_score)), ncol = 1)
# this is S1_hat
exp_risk_score_X <- exp_risk_score * X
at_risk_X <- fast_risk_sets(exp_risk_score_X)
at_risk_X_X <- fast_risk_sets(exp_risk_score_X * X)
list(stat = stat,
time = time,
weight = weight,
S0 = at_risk,
S1 = at_risk_X,
exp_risk_score = exp(risk_score),
weighted_exp_risk_score = exp_risk_score,
S2 = at_risk_X_X,
X = X)
}
coxfit <- survival::coxph(survival::Surv(stat_time, stat) ~ X1, data = my_samp)
parts <- BB(survival::Surv(stat_time, stat) ~ X1, data = my_samp,
beta = coef(coxfit), weight = my_samp$weight)
calc_ui2 <- function(parts){
n <- length(parts$stat)
# first term is the same
term1 <- with(parts, {
stat * (X - S1/S0)
})
# divide each exp(beta*X) by the series of risk sets.
p1 <- with(parts, {
tcrossprod(exp_risk_score, 1/S0)
})
p2 <- with(parts, {
# replicate X n times to make a n*n matrix from n*1 X.
# minus S0/S1, which is also n*1 from each row
Matrix(as.numeric(X), ncol = n, nrow = n) - Matrix(as.numeric(S1/S0), ncol = n, nrow = n, byrow = TRUE)
})
# yi is the indicator I(ti >= tj). Each ti needs to be compared to all tj
# because ti is sorted, this should be an upper triangle matrix (if no ties)
yi <- with(parts, {
Matrix(rep(time, each = n) <= rep(time, n), ncol = n, nrow = n, byrow = TRUE)
})
# matrix with n reps of stat, as rows.
dj <- with(parts, {
Matrix(stat, nrow = n, ncol = n, byrow = TRUE)
})
# matrix with n reps of weights, as rows.
wj <- with(parts, {
Matrix(weight, nrow = n, ncol = n, byrow = TRUE)
})
# the second term is the row sums after taking the product of these matricies
# term2 <- rowSums(-dj * wj * yi * p1 * p2)
term2 <- -dj * wj * yi * p1 * p2
# term1 + term2
# to compare to the ui matrix, filled cell by cell.
term2
}
r2 <- calc_ui2(parts)
svycoxme_path <- file.path(Sys.getenv("OneDriveCommercial"), "Documents/PhD_local/svycoxme")
devtools::load_all(svycoxme_path)
k <- 5000
nk <- 10
n_clusters_in_sample <- 40
theta <- 0
true_coefs = c(1, -0.7, 0.5)
the_data <- one_dataset(~X1 + X2 + X3 + (1 | M),
dists = list(X1 = ~rnorm(n),
X2 = ~rep(rnorm(k), each = nk),
X3 = ~rep(rbinom(k, 1, 0.5), each = nk),
M = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = true_coefs,
random_effect_variance = c(M=theta)
)
pop <- dplyr::mutate(the_data, id = M)
devtools::load_all(".")
k <- 5000
nk <- 10
n_clusters_in_sample <- 40
cluster_str <- data.frame(table(Size = rpois(2500, 2) + 6)) |>
dplyr::filter(Freq >=10)
cluster_str_list <- split(cluster_str, seq(nrow(cluster_str)))
max_cluster_digits <- max(nchar(as.character(cluster_str$Size)))
max_cluster_freq_digits <- max(nchar(as.character(cluster_str$Freq)))
set.seed(949742)
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + (1 | M1),
dists = list(X1 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(1),
random_effect_variance = list(M1 = 0)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
names(parts)
length(parts$stat)
i = 250
X[i]
parts$X[i]
svycoxme_path <- file.path(Sys.getenv("OneDriveCommercial"), "Documents/PhD_local/svycoxme")
devtools::load_all(svycoxme_path)
k <- 5000
nk <- 10
n_clusters_in_sample <- 40
theta <- 0
true_coefs = c(1, -0.7, 0.5)
the_data <- one_dataset(~X1 + X2 + X3 + (1 | M),
dists = list(X1 = ~rnorm(n),
X2 = ~rep(rnorm(k), each = nk),
X3 = ~rep(rbinom(k, 1, 0.5), each = nk),
M = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = true_coefs,
random_effect_variance = c(M=theta)
)
pop <- dplyr::mutate(the_data, id = M)
# sample from it
# one cluster sample
samp_cluster_ids <- unique(pop$id)[sample.int(k, n_clusters_in_sample)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
## for memory reasons
rm(pop)
rm(the_data)
my_samp$prob <- (n_clusters_in_sample/k)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
my_samp <- my_samp[order(my_samp$stat_time), ]
coxph_fit <- survival::coxph(survival::Surv(stat_time, stat)~ X1 + X2 + X3,
data = my_samp, weights = my_samp$rweights)
parts <- make_parts(coxph_fit, my_samp, weights = my_samp$weights)
parts
names(parts)
i = 250
parts$X[i]
coxph_fit <- survival::coxph(survival::Surv(stat_time, stat)~ X1 + X2 + X3,
data = my_samp, weights = my_samp$rweights)
parts <- make_parts(coxph_fit, my_samp, weights = my_samp$weights)
names(parts)
parts$X
parts$X[i, ]
=======
identical(resid, resid2)
# fit a mixed effects model. modify to give results of the random effects model.
coxmefit = coxme::coxme(Surv(start_time, event_time, status) ~ X1 + X2 + (1 | group_id),
data = dset, x = TRUE, y = TRUE, ties = "breslow")
coxmefit$coefficients <- coef(coxfit)
coxmefit$frail
coxme::random.effects(coxmefit)
coef(coxmefit)
coef(coxfit)
parts <- make_parts.coxme(coxmefit, dset)
lapply(parts, is.matrix)
# fit a mixed effects model. modify to give results of the random effects model.
coxmefit = coxme::coxme(Surv(start_time, event_time, status) ~ X1 + X2 + (1 | group_id),
data = dset, x = TRUE, y = TRUE, ties = "breslow")
parts <- make_parts.coxme(coxmefit, dset)
lapply(parts, is.matrix)
rr <- with(parts,{
C_calc_ui(time_start = time_start,
time_stop = time_stop,
stat = stat,
weights = weights,
exp_risk_score = exp_risk_score,
S0 = S0,
S1_X = S1_X,
X = X,
weighted = TRUE)
})
rr
# can coxme have strata
coxmefit = coxme::coxme(Surv(start_time, stop_time, status) ~ X1 + X2 + (1 | M) + strata(strat),
data = dset, x = TRUE, y = TRUE, ties = "breslow")
n = 1000
X = data.frame(X1 = rnorm(n),
X2 = rnorm(n),
M = rep(c(0,1), each = n/2),
id = seq_len(n))
dset = draw_event_times(formula = Surv(start_time, stop_time, status) ~ X1 + X2 + (1 | M),
data = X,
coefficients = c(X1 = 1, X2 = 0.5),
random_effect_variance = c(M = 0),
id = id,
baseline_hazard = 1,
event = "single")
dset = dplyr::left_join(dset, dplyr::select(X, id, M), by = dplyr::join_by(id))
dset$strat = rep(c(1:2), n/2)
# can coxme have strata
coxmefit = coxme::coxme(Surv(start_time, stop_time, status) ~ X1 + X2 + (1 | M) + strata(strat),
data = dset, x = TRUE, y = TRUE, ties = "breslow")
coxmefit$strata
residuals2.coxme
# compare residuals using agscore from coxph and mine.
# get a model fit.
library(survival)
k = 200 # clusters
nk = 5 # cluster size
N = nk * k # total obs
# clusters sampled
n = 100
baserate = 0.5
beta = c(0.5, -0.25)
theta = 0.5
b = rnorm(k, sd = theta)
Z1 = rnorm(N) # obs level
Z2 = rep(rnorm(k), each = nk)  # cluster level
group_id = rep(1:k, each = nk)
Z1_mean = tapply(Z1, group_id, FUN = mean)
Z2_mean = tapply(Z2, group_id, FUN = mean)
mu_X1 = 0.5 * Z1
mu_X2 = 0.5 * (Z1_mean + Z2_mean)
X1 = rnorm(N, mean = mu_X1, sd = 0.25)
X2 = rep(rnorm(k, mean = mu_X2, sd = 0.5), each = nk)
rate = baserate * exp(cbind(X1, X2)%*% matrix(beta) + rep(b, each = nk))
event_time = rexp(N, rate)
dset = data.frame(event_time, stat = 1, X1, X2, Z1, Z2, group_id)
dset$start_time = 0
dset <- dset %>%
dplyr::group_by(group_id) %>%
dplyr::mutate(t_stop = cumsum(event_time)) %>%
dplyr::mutate(t_start = dplyr::lag(t_stop, default = 0), .before = t_stop) %>%
dplyr::ungroup()
coxmefit = coxph(Surv(t_start, t_stop, stat) ~ X1 + X2 + (1 | group_id), data = dset,
x = TRUE, y = TRUE, ties = "breslow")
coef(coxfit)
coef(coxmefit)
coxmefit = coxme(Surv(t_start, t_stop, stat) ~ X1 + X2 + (1 | group_id), data = dset,
x = TRUE, y = TRUE, ties = "breslow")
library(coxme)
coxfit = coxph(Surv(t_start, t_stop, stat) ~ X1 + X2, data = dset,
x = TRUE, y = TRUE, ties = "breslow")
coxmefit = coxme(Surv(t_start, t_stop, stat) ~ X1 + X2 + (1 | group_id), data = dset,
x = TRUE, y = TRUE, ties = "breslow")
coef(coxfit)
coef(coxmefit)
type = "score"
otype = "score"
n <- length(coxfit$residuals)
rr <- coxfit$residuals
y <- coxfit$y
x <- coxfit[["x"]]
vv <- drop(coxfit$naive.var)
if (is.null(vv))
vv <- drop(coxfit$var)
weights <- coxfit$weights
if (is.null(weights))
weights <- rep(1, n)
strat <- coxfit$strata
method <- coxfit$method
Terms <- coxfit$terms
strats <- attr(Terms, "specials")$strata
ny <- ncol(y)
status <- y[, ny, drop = TRUE]
nvar <- ncol(x)
# set up strata, order.
if (is.null(strat)) {
ord <- order(y[, ny - 1], -status)
newstrat <- integer(n)
istrat <- integer(n)
} else {
istrat <- as.integer(strat)
ord <- order(istrat, y[, ny - 1], -status)
newstrat <- c(diff(as.numeric(istrat[ord])) !=
0, 1)
}
newstrat[n] <- 1
x <- x[ord, ]
y <- y[ord, ]
coxmefit$linear.predictor
type = "score"
otype = "score"
n <- length(coxfit$residuals)
rr <- coxfit$residuals
y <- coxfit$y
x <- coxfit[["x"]]
vv <- drop(coxfit$naive.var)
if (is.null(vv))
vv <- drop(coxfit$var)
weights <- coxfit$weights
if (is.null(weights))
weights <- rep(1, n)
strat <- coxfit$strata
method <- coxfit$method
Terms <- coxfit$terms
strats <- attr(Terms, "specials")$strata
ny <- ncol(y)
status <- y[, ny, drop = TRUE]
nvar <- ncol(x)
# set up strata, order.
if (is.null(strat)) {
ord <- order(y[, ny - 1], -status)
newstrat <- integer(n)
istrat <- integer(n)
} else {
istrat <- as.integer(strat)
ord <- order(istrat, y[, ny - 1], -status)
newstrat <- c(diff(as.numeric(istrat[ord])) !=
0, 1)
}
newstrat[n] <- 1
x <- x[ord, ]
y <- y[ord, ]
# score <- exp(coxfit$linear.predictors)[ord]
score <- exp(coxmefit$linear.predictors)[ord]
coxmefit$linear.predictors
exp(coxmefit$linear.predictor)
# score <- exp(coxfit$linear.predictors)[ord]
score <- exp(coxmefit$linear.predictor)[ord]
istrat <- istrat[ord]
if (ny == 3) {
if (is.null(strat))
sort1 <- order(y[, 1])
else sort1 <- order(istrat, y[, 1])
}
storage.mode(y) <- storage.mode(x) <- "double"
storage.mode(newstrat) <- "integer"
storage.mode(score) <- storage.mode(weights) <- "double"
resid <- .Call(survival:::Cagscore3, y, x, istrat, score, weights[ord],
as.integer(method == "efron"), sort1 - 1L)
if (nvar > 1) {
rr <- matrix(0, n, nvar)
rr[ord, ] <- resid
dimnames(rr) <- list(names(coxfit$residuals), names(coxfit$coefficients))
}
my_tstart = y[, 1, drop = TRUE]
my_tend = y[, 2, drop = TRUE]
my_status = y[, 3, drop = TRUE]
resid2 = svycoxme::agscore3(my_tstart, my_tend, my_status, covar = x, strata = istrat,
score = score, weights = weights[ord], sort1 = sort1 - 1L,
method = as.integer(method == "efron"))
identical(resid, resid2)
parts <- make_parts.coxme(coxmefit, dset)
rr <- with(parts,{
C_calc_ui(time_start = time_start,
time_stop = time_stop,
stat = stat,
weights = weights,
exp_risk_score = exp_risk_score,
S0 = S0,
S1_X = S1_X,
X = X,
weighted = TRUE)
})
rr
residuals2.coxme
residuals.coxme
resid3 = residuals.coxme(coxmefit, data = dset)
# compare residuals using agscore from coxph and mine.
# get a model fit.
library(survival)
k = 200 # clusters
nk = 5 # cluster size
N = nk * k # total obs
# clusters sampled
n = 100
baserate = 0.5
beta = c(0.5, -0.25)
theta = 0.5
b = rnorm(k, sd = theta)
Z1 = rnorm(N) # obs level
Z2 = rep(rnorm(k), each = nk)  # cluster level
group_id = rep(1:k, each = nk)
Z1_mean = tapply(Z1, group_id, FUN = mean)
Z2_mean = tapply(Z2, group_id, FUN = mean)
mu_X1 = 0.5 * Z1
mu_X2 = 0.5 * (Z1_mean + Z2_mean)
X1 = rnorm(N, mean = mu_X1, sd = 0.25)
X2 = rep(rnorm(k, mean = mu_X2, sd = 0.5), each = nk)
rate = baserate * exp(cbind(X1, X2)%*% matrix(beta) + rep(b, each = nk))
event_time = rexp(N, rate)
dset = data.frame(event_time, stat = 1, X1, X2, Z1, Z2, group_id)
dset$start_time = 0
dset <- dset %>%
dplyr::group_by(group_id) %>%
dplyr::mutate(t_stop = cumsum(event_time)) %>%
dplyr::mutate(t_start = dplyr::lag(t_stop, default = 0), .before = t_stop) %>%
dplyr::ungroup()
coxfit = coxph(Surv(t_start, t_stop, stat) ~ X1 + X2, data = dset,
x = TRUE, y = TRUE, ties = "breslow")
coxmefit = coxme(Surv(t_start, t_stop, stat) ~ X1 + X2 + (1 | group_id), data = dset,
x = TRUE, y = TRUE, ties = "breslow")
coef(coxfit)
coef(coxmefit)
coxfit$residuals
type = "score"
otype = "score"
n <- length(coxfit$residuals)
rr <- coxfit$residuals
y <- coxfit$y
x <- coxfit[["x"]]
vv <- drop(coxfit$naive.var)
if (is.null(vv))
vv <- drop(coxfit$var)
weights <- coxfit$weights
if (is.null(weights))
weights <- rep(1, n)
strat <- coxfit$strata
method <- coxfit$method
Terms <- coxfit$terms
strats <- attr(Terms, "specials")$strata
ny <- ncol(y)
status <- y[, ny, drop = TRUE]
nvar <- ncol(x)
# set up strata, order.
if (is.null(strat)) {
ord <- order(y[, ny - 1], -status)
newstrat <- integer(n)
istrat <- integer(n)
} else {
istrat <- as.integer(strat)
ord <- order(istrat, y[, ny - 1], -status)
newstrat <- c(diff(as.numeric(istrat[ord])) !=
0, 1)
}
newstrat[n] <- 1
x <- x[ord, ]
y <- y[ord, ]
# score <- exp(coxfit$linear.predictors)[ord]
score <- exp(coxmefit$linear.predictor)[ord]
istrat <- istrat[ord]
if (ny == 3) {
if (is.null(strat))
sort1 <- order(y[, 1])
else sort1 <- order(istrat, y[, 1])
}
storage.mode(y) <- storage.mode(x) <- "double"
storage.mode(newstrat) <- "integer"
storage.mode(score) <- storage.mode(weights) <- "double"
resid <- .Call(survival:::Cagscore3, y, x, istrat, score, weights[ord],
as.integer(method == "efron"), sort1 - 1L)
if (nvar > 1) {
rr <- matrix(0, n, nvar)
rr[ord, ] <- resid
dimnames(rr) <- list(names(coxfit$residuals), names(coxfit$coefficients))
}
my_tstart = y[, 1, drop = TRUE]
my_tend = y[, 2, drop = TRUE]
my_status = y[, 3, drop = TRUE]
resid2 = svycoxme::agscore3(my_tstart, my_tend, my_status, covar = x, strata = istrat,
score = score, weights = weights[ord], sort1 = sort1 - 1L,
method = as.integer(method == "efron"))
identical(resid, resid2)
resid3 = residuals.coxme(coxmefit, data = dset)
identical(resid, resid3)
residuals.coxph
survival:::residuals.coxph
survival:::Ccoxscore2
y
coxfit = coxph(Surv(event_time, stat) ~ X1 + X2, data = dset,
x = TRUE, y = TRUE, ties = "breslow")
coxmefit = coxme(Surv(event_time, stat) ~ X1 + X2 + (1 | group_id), data = dset,
x = TRUE, y = TRUE, ties = "breslow")
coef(coxfit)
coef(coxmefit)
coxfit$residuals
type = "score"
otype = "score"
n <- length(coxfit$residuals)
rr <- coxfit$residuals
y <- coxfit$y
x <- coxfit[["x"]]
vv <- drop(coxfit$naive.var)
if (is.null(vv))
vv <- drop(coxfit$var)
weights <- coxfit$weights
if (is.null(weights))
weights <- rep(1, n)
strat <- coxfit$strata
method <- coxfit$method
Terms <- coxfit$terms
strats <- attr(Terms, "specials")$strata
ny <- ncol(y)
status <- y[, ny, drop = TRUE]
nvar <- ncol(x)
# set up strata, order.
if (is.null(strat)) {
ord <- order(y[, ny - 1], -status)
newstrat <- integer(n)
istrat <- integer(n)
} else {
istrat <- as.integer(strat)
ord <- order(istrat, y[, ny - 1], -status)
newstrat <- c(diff(as.numeric(istrat[ord])) !=
0, 1)
}
newstrat[n] <- 1
x <- x[ord, ]
y <- y[ord, ]
# score <- exp(coxfit$linear.predictors)[ord]
score <- exp(coxmefit$linear.predictor)[ord]
istrat <- istrat[ord]
if (ny == 3) {
if (is.null(strat))
sort1 <- order(y[, 1])
else sort1 <- order(istrat, y[, 1])
}
storage.mode(y) <- storage.mode(x) <- "double"
storage.mode(newstrat) <- "integer"
storage.mode(score) <- storage.mode(weights) <- "double"
resid <- .Call(Ccoxscore2, y, x, istrat, score, weights[ord],
as.integer(method == "efron"))
resid <- .Call(survival:::Ccoxscore2, y, x, istrat, score, weights[ord],
as.integer(method == "efron"))
resid
if (nvar > 1) {
rr <- matrix(0, n, nvar)
rr[ord, ] <- resid
dimnames(rr) <- list(names(coxfit$residuals), names(coxfit$coefficients))
}
my_tstart = y[, 1, drop = TRUE]
my_tend = y[, 2, drop = TRUE]
identical(resid, resid2)
resid
resid2
head(resid)
head(resid2)
k = 200 # clusters
nk = 5 # cluster size
N = nk * k # total obs
# clusters sampled
n = 100
baserate = 0.5
beta = c(0.5, -0.25)
theta = 0.5
b = rnorm(k, sd = theta)
Z1 = rnorm(N) # obs level
Z2 = rep(rnorm(k), each = nk)  # cluster level
group_id = rep(1:k, each = nk)
Z1_mean = tapply(Z1, group_id, FUN = mean)
Z2_mean = tapply(Z2, group_id, FUN = mean)
mu_X1 = 0.5 * Z1
mu_X2 = 0.5 * (Z1_mean + Z2_mean)
X1 = rnorm(N, mean = mu_X1, sd = 0.25)
X2 = rep(rnorm(k, mean = mu_X2, sd = 0.5), each = nk)
rate = baserate * exp(cbind(X1, X2)%*% matrix(beta) + rep(b, each = nk))
event_time = rexp(N, rate)
dset = data.frame(event_time, stat = 1, X1, X2, Z1, Z2, group_id)
dset$start_time = 0
dset <- dset %>%
dplyr::group_by(group_id) %>%
dplyr::mutate(t_stop = cumsum(event_time)) %>%
dplyr::mutate(t_start = dplyr::lag(t_stop, default = 0), .before = t_stop) %>%
dplyr::ungroup()
coxfit = coxph(Surv(event_time, stat) ~ X1 + X2, data = dset,
x = TRUE, y = TRUE, ties = "breslow")
coxmefit = coxme(Surv(event_time, stat) ~ X1 + X2 + (1 | group_id), data = dset,
x = TRUE, y = TRUE, ties = "breslow")
coef(coxfit)
coef(coxmefit)
coxfit$residuals
type = "score"
otype = "score"
n <- length(coxfit$residuals)
rr <- coxfit$residuals
y <- coxfit$y
x <- coxfit[["x"]]
vv <- drop(coxfit$naive.var)
if (is.null(vv))
vv <- drop(coxfit$var)
weights <- coxfit$weights
if (is.null(weights))
weights <- rep(1, n)
strat <- coxfit$strata
method <- coxfit$method
Terms <- coxfit$terms
strats <- attr(Terms, "specials")$strata
ny <- ncol(y)
status <- y[, ny, drop = TRUE]
nvar <- ncol(x)
# set up strata, order.
if (is.null(strat)) {
ord <- order(y[, ny - 1], -status)
newstrat <- integer(n)
istrat <- integer(n)
} else {
istrat <- as.integer(strat)
ord <- order(istrat, y[, ny - 1], -status)
newstrat <- c(diff(as.numeric(istrat[ord])) !=
0, 1)
}
newstrat[n] <- 1
x <- x[ord, ]
y <- y[ord, ]
score <- exp(coxfit$linear.predictors)[ord]
# score <- exp(coxmefit$linear.predictor)[ord]
istrat <- istrat[ord]
if (ny == 3) {
if (is.null(strat))
sort1 <- order(y[, 1])
else sort1 <- order(istrat, y[, 1])
}
storage.mode(y) <- storage.mode(x) <- "double"
storage.mode(newstrat) <- "integer"
storage.mode(score) <- storage.mode(weights) <- "double"
resid <- .Call(survival:::Ccoxscore2, y, x, istrat, score, weights[ord],
as.integer(method == "efron"))
y
head(y)
ncol(y)
coxfit = coxph(Surv(start_time, event_time, stat) ~ X1 + X2, data = dset,
x = TRUE, y = TRUE, ties = "breslow")
n <- length(coxfit$residuals)
rr <- coxfit$residuals
y <- coxfit$y
x <- coxfit[["x"]]
vv <- drop(coxfit$naive.var)
if (is.null(vv))
vv <- drop(coxfit$var)
weights <- coxfit$weights
if (is.null(weights))
weights <- rep(1, n)
strat <- coxfit$strata
method <- coxfit$method
Terms <- coxfit$terms
strats <- attr(Terms, "specials")$strata
ny <- ncol(y)
status <- y[, ny, drop = TRUE]
nvar <- ncol(x)
# set up strata, order.
if (is.null(strat)) {
ord <- order(y[, ny - 1], -status)
newstrat <- integer(n)
istrat <- integer(n)
} else {
istrat <- as.integer(strat)
ord <- order(istrat, y[, ny - 1], -status)
newstrat <- c(diff(as.numeric(istrat[ord])) !=
0, 1)
}
newstrat[n] <- 1
x <- x[ord, ]
y <- y[ord, ]
score <- exp(coxfit$linear.predictors)[ord]
# score <- exp(coxmefit$linear.predictor)[ord]
istrat <- istrat[ord]
if (ny == 3) {
if (is.null(strat))
sort1 <- order(y[, 1])
else sort1 <- order(istrat, y[, 1])
}
storage.mode(y) <- storage.mode(x) <- "double"
storage.mode(newstrat) <- "integer"
storage.mode(score) <- storage.mode(weights) <- "double"
my_tstart = y[, 1, drop = TRUE]
my_tend = y[, 2, drop = TRUE]
my_status = y[, 3, drop = TRUE]
resid2 = svycoxme::agscore3(my_tstart, my_tend, my_status, covar = x, strata = istrat,
score = score, weights = weights[ord], sort1 = sort1 - 1L,
method = as.integer(method == "efron"))
identical(resid, resid2)
head(resid)
head(resid2)
identical(resid, resid2)
all.equal(resid, resid2)
>>>>>>> Stashed changes
