coefficients = true_coefs,
random_effect_variance = c(M=specs$theta)
)
pop <- dplyr::mutate(the_data, id = M)
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
# for memory reasons
rm(list = c('pop', 'the_data'))
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
my_samp <- my_samp[order(my_samp$stat_time), ]
coxme_fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + X3 + (1|id), data = my_samp)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
my_des_jackknife <- as.svrepdesign(my_des, type = "JK1")
my_des_bootstrap <- as.svrepdesign(my_des, type = "bootstrap", replicates = 200)
svycoxme_fit_jackknife <- svycoxme(survival::Surv(stat_time, stat)~ X1 + X2 + X3 + (1|id), des = my_des_jackknife)
svycoxme_fit <- svycoxme(survival::Surv(stat_time, stat)~ X1 + X2 + X3 + (1|id), des = my_des)
svycoxme_fit_bootstrap <- svycoxme(survival::Surv(stat_time, stat)~ X1 + X2 + X3 + (1|id), des = my_des_bootstrap)
list(
specs = specs,
svycoxme_var = diag(vcov(svycoxme_fit)),
svycoxme_var_jackknife = diag(vcov(svycoxme_fit_jackknife)),
svycoxme_var_bootstrap = diag(vcov(svycoxme_fit_bootstrap)),
fisher_var_unweighted = diag(vcov(coxme_fit)),
coefs = coef(coxme_fit))
}
# see: https://stackoverflow.com/questions/4948361/how-do-i-save-warnings-and-errors-as-output-from-a-function
myTryCatch <- function(expr) {
warn <- err <- NULL
value <- withCallingHandlers(
tryCatch(expr, error=function(e) {
err <<- e
NULL
}), warning=function(w) {
warn <<- w
invokeRestart("muffleWarning")
})
#drop call from error
err$call <- NULL
list(value=value, warning=warn, error=err)
}
try_one_rep <- function(specs){
stream <- .Random.seed
r <- myTryCatch(one_rep(specs))
attr(r, "stream") <- stream
attr(r, "specs") <- specs
r
}
results_path <- file.path(Sys.getenv("OneDriveCommercial"), "PhD/outputs/simulations/data/svycoxme_variances_6.rds")
res <- readr::read_rds(results_path)
# set stream to id 107
res107_newstream <- try_one_rep(specs = param_combos_list[[107]])
res107_newstream
devtools::load_all(".")
# set stream to id 107
res107_newstream <- try_one_rep(specs = param_combos_list[[107]])
# set stream to id 107
res107_newstream
coxme::coxme.control()
devtools::load_all(".")
# set stream to id 107
res107_newstream <- try_one_rep(specs = param_combos_list[[107]])
assign(".Random.seed", attr(res[[107]], "stream"))
res107_oldstream <- try_one_rep(specs = param_combos_list[[107]])
# define one rep
one_rep <- function(specs){
# generate a population, sample from it, calculate the things.
# generate population
k <- specs$n_clusters
nk <- specs$cluster_size
the_data <- one_dataset(~X1 + X2 + X3 + (1 | M),
dists = list(X1 = ~rnorm(n),
X2 = ~rep(rnorm(k), each = nk),
X3 = ~rep(rbinom(k, 1, 0.5), each = nk),
M = ~rep(1:k, each = nk)),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = true_coefs,
random_effect_variance = c(M=specs$theta)
)
pop <- dplyr::mutate(the_data, id = M)
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
# for memory reasons
rm(list = c('pop', 'the_data'))
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
my_samp <- my_samp[order(my_samp$stat_time), ]
coxme_fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + X3 + (1|id), data = my_samp)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
my_des_jackknife <- as.svrepdesign(my_des, type = "JK1")
my_des_bootstrap <- as.svrepdesign(my_des, type = "bootstrap", replicates = 200)
svycoxme_fit_jackknife <- svycoxme(survival::Surv(stat_time, stat)~ X1 + X2 + X3 + (1|id), des = my_des_jackknife)
svycoxme_fit <- svycoxme(survival::Surv(stat_time, stat)~ X1 + X2 + X3 + (1|id), des = my_des)
svycoxme_fit_bootstrap <- svycoxme(survival::Surv(stat_time, stat)~ X1 + X2 + X3 + (1|id), des = my_des_bootstrap,
control = coxme::coxme.control(sparse = c(200, 0.001)))
list(
specs = specs,
svycoxme_var = diag(vcov(svycoxme_fit)),
svycoxme_var_jackknife = diag(vcov(svycoxme_fit_jackknife)),
svycoxme_var_bootstrap = diag(vcov(svycoxme_fit_bootstrap)),
fisher_var_unweighted = diag(vcov(coxme_fit)),
coefs = coef(coxme_fit))
}
assign(".Random.seed", attr(res[[107]], "stream"))
res107_moreReps <- try_one_rep(specs = param_combos_list[[107]])
res107_oldstream
res107_moreReps
results_path <- file.path(Sys.getenv("OneDriveCommercial"), "PhD/outputs/simulations/data/svycoxme_variances_6.rds")
res <- readr::read_rds(results_path)
error_messages <- lapply(res, "[[", "error")
warning_messages <- lapply(res, "[[", "warning")
returned_values <- lapply(res, "[[", "value")
is.error <- sapply(error_messages, inherits, "error")
is.warning <- sapply(warning_messages, inherits, "warning")
table(is.error) |> prop.table()
table(is.warning)
results_with_warnings <- res[is.warning]
non_error_fits <- returned_values[!is.error]
non_error_fits[[1]]
shape_res <- function(one_fit){
covars <- names(one_fit$coefs)
tibble::tibble(
method = rep(c("svycoxme_var", "svycoxme_var_jackknife", "svycoxme_var_bootstrap",
"fisher_unweighted"), each = length(covars)),
covariate = rep(covars, 4),
n_clusters_in_sample = one_fit$specs$n_clusters_in_sample,
cluster_size = one_fit$specs$cluster_size,
theta = one_fit$specs$theta,
coefs = rep(one_fit$coefs, 4),
true_coefs = rep(c(1, -0.7, 0.5), 4),
variance = with(one_fit, c(svycoxme_var, svycoxme_var_jackknife, svycoxme_var_bootstrap,
fisher_var_unweighted)),
lower = one_fit$coefs + qnorm(0.025) * sqrt(variance),
upper = one_fit$coefs + qnorm(0.975) * sqrt(variance),
hit = lower < true_coefs & upper > true_coefs
)
}
shape_res(non_error_fits[[1]])
df <- plyr::ldply(non_error_fits, shape_res)
library(tidyverse)
# coverage by number of clusters, by covariate and theta, and method.
coverage_summary2 <- df %>%
group_by(method, theta, covariate, n_clusters_in_sample)  %>%
summarise(coverage = mean(hit, na.rm = TRUE),
n = n(),
coverage_se = sqrt(coverage * (1-coverage) / n),
coverage_lower = coverage + qnorm(0.025) * coverage_se,
coverage_upper = coverage + qnorm(0.975) * coverage_se,
mean_coef = mean(coefs),
true_coefs = first(true_coefs),
empirical_se = sqrt(mean((coefs-true_coefs)^2)),
estimated_se = mean(sqrt(variance)),
prop_nas = sum(is.na(hit))/n,
.groups = "drop")
coverage_summary2 %>%
select(method, n_clusters_in_sample, coverage, coverage_lower, coverage_upper, covariate, theta) %>%
filter(covariate == "X1") %>%
ggplot(aes(n_clusters_in_sample, coverage, ymin = coverage_lower, ymax = coverage_upper, colour = method)) +
geom_line() +
geom_errorbar(width = 0.09) +
facet_grid(rows = vars(method), cols = vars(theta)) +
geom_hline(yintercept = 0.95)
EmpSE <- function(theta){
theta_bar = mean(theta)
sqrt( sum((theta-mean(theta))^2)/(length(theta)-1) )
}
empirical_se_vs_mean <- df %>%
group_by(covariate, method, theta, n_clusters_in_sample) %>%
summarise(empirical_se = EmpSE(coefs),
mean_se = mean(sqrt(variance), na.rm = TRUE),
diff = empirical_se - mean_se,
.groups = "drop")
empirical_se_vs_mean %>%
filter(covariate == "X1") %>%
ggplot(aes(n_clusters_in_sample, diff, colour = method)) +
geom_line() +
facet_grid(rows = vars(method), cols = vars(theta))
library(survival)
draw_event_times <- function(formula, data, coefficients = c(), random_effect_variance = list(), id,
baseline_hazard = 1, t = 0, event = c("single", "recurrent"),
origin = 0, end_of_follow_up = NULL){
Call <- match.call()
event <- match.arg(event)
Call_id <- Call[["id"]]
if (is.null(Call_id)){
stop("id required")
} else if (is.name(Call_id)) {
idx <- as.character(Call_id)
}
if (is.null(end_of_follow_up) & event == "recurrent") stop("end_of_follow_up must be specified for recurrent events")
fixed_terms <- stats::terms(lme4::nobars(formula))
# These are the fixed term variables in the formula, even if there are interactions.
fixed_term_variables <- colnames(attr(fixed_terms, "factors"))
bars = lme4::findbars(formula)
barnames = lme4:::barnames(bars)
random_terms = terms(as.formula(paste("~", paste(c(1, barnames), collapse = "+"))))
random_term_variables <- rownames(attr(random_terms, "factors"))
variables <- c(fixed_term_variables, random_term_variables)
if(attr(fixed_terms, "response") == 0) stop("formula must have a Surv response")
# strata
# find the strata spec in the form.
# make sure there is a baseline hazard for each stratum
# clustering. dont allow a cluster() call in the formula. instead ask for (1|cluster_id).
# Or allow it and covert it.
# will need an associated random effect.
# cluster in the sandwich means that the variances are cluster-specific. need to allow input of variance structure?
# data will have start and stop times, as specified, but only if there is time-varying covariates.
# otherwise there wont be times.
# and there wont be a stat variable.
Surv_Call <- Call$formula[[2]]
# get time names out of the Call.
# cant use the attribute, because the data need the variables in the call before calling model.frame.
# but I'll use the length of the Surv_call instead. This will probably break if anything but one or two times
# are passed to Surv. Maybe I need to evaluate Surv? Nope. need the vars first.
# Surv_evaluated <- eval(Surv_Call)
# if(attr(model_response, "type") == "counting"){
if(length(Surv_Call) == 4){
start_name <- Surv_Call[[2]]
stop_name <- Surv_Call[[3]]
status_name <- Surv_Call[[4]]
Surv_vars <- c(start_name, stop_name, status_name)
# } else if(attr(model_response, "type") == "right"){
} else if(length(Surv_Call) == 3) {
start_name <- "origin"
stop_name <- Surv_Call[[2]]    # actually called time, not stop
status_name <- Surv_Call[[3]]
if(start_name == stop_name) {stop("You need to call your event times something other than, 'origin'")}
Surv_vars <- c(start_name, stop_name, status_name)
}
# convert Surv_vars from a list of names to a character vector
Surv_vars <- sapply(Surv_vars, as.character)
# check if variables in the Surv() Call are already in the data set.
Surv_vars_in_data <- Surv_vars %in% colnames(data)
# add the ones that aren't
# need a message or warning? Probably not. Just explain in documentation
# message(paste(Surv_vars[Surv_vars_in_data], collapse = ", "), paste(" will be modified"))
if(any(!Surv_vars_in_data)){
data[Surv_vars[!Surv_vars_in_data]] <- double(length = nrow(data))
}
model_frame <- model.frame(lme4:::getFixedFormula(formula), data)
model_response <- model.response(model_frame)
X <- model_frame[, -1, drop = FALSE]
# response_type = attr(response, 'type')
#
# if(response_type == "right"){
#
#   time_stop = response[,"time"]
#   time_start = rep(0, length(time_stop))
#   stat = response[,'status']
#
# } else if(response_type == "counting") {
#
#   time_start = response[,"start"]
#   time_stop = response[,"stop"]
#   stat = response[,"status"]
#
# } else {
#
#   stop("response type is not supported")
#
# }
lp_random_effects <- list()
if(length(barnames)) {
data$ytemp <- 1
formula <- update(formula, ytemp ~ .)
parsed_data <- lme4::lFormula(formula, data = data)
data <- dplyr::select(data, -ytemp)
# for each random effect term, need to generate the random effect terms, and join them to the data.
# if terms don't exist in the data, they will be in flist.
re_terms <- names(parsed_data$reTrms$cnms)
names(re_terms) <- re_terms
if(length(re_terms) != length(random_effect_variance))
stop("I need one variance for each random effect term. Note that (1 | M1/M2) breaks down into M1, M2 and M1:M2")
# save the seed. It will be restored after this.
lp_random_effects_list <- lapply(re_terms, function(re){
re_factor <- parsed_data$reTrms$flist[[re]]
group_counts <- table(re_factor)
# set a seed
# if(!is.null(random_effect_seed)) set.seed(random_effect_seed[[re]])
b <- rnorm(length(group_counts), mean = 0, sd = sqrt(random_effect_variance[[re]]))
b_rep <- dplyr::left_join(data.frame(re_name = re_factor),
data.frame(re_name = names(group_counts), re = b), by = "re_name")
# This is the random effect repeated for each observation
re <- b_rep$re
# this is the unique random effects
names(b) <- names(group_counts)
attr(re, "random_effects") <- b
re
})
lp_random_effects <- Reduce("cbind", lp_random_effects_list)
random_effects <- lapply(lp_random_effects_list, attr, "random_effects")
# reset randomness
# set.seed(arbitraty_seed)
} else {
random_effects <- NULL
}
# transpose non-zero length coefficients
if(length(coefficients))
coefficients <- t(coefficients)
risk_score_parts_list <- list(fixed = tcrossprod(as.matrix(data[, fixed_term_variables]), coefficients),
random = lp_random_effects)
risk_score_parts_list <- risk_score_parts_list[lapply(risk_score_parts_list, length)>0]
risk_score_parts_matrix <- Reduce(cbind, risk_score_parts_list)
if(!is.null(risk_score_parts_matrix)) {
risk_score <- .rowSums(risk_score_parts_matrix,
m = nrow(risk_score_parts_matrix), n = ncol(risk_score_parts_matrix))
} else {
risk_score <- rep(0, length(error))
data <- data.frame(stat_time = numeric(length(error)))
}
# this is the old way.
# vars_df$stat_time <- exp(-risk_score) * error
# instead
# this wont work generally.
# there are four scenarios:
# no changes in covariates
# no one event
# no changes in covariates,
# multiple events
# changes in covariates,
# one event
# changes in covariates,
# multiple events
# make the time accounting consistent. so always time_start and time_stop.
response_type = attr(model_response, 'type')
if(response_type == "right"){
# time_stop = response[,"time"]
# time_start = rep(0, length(time_stop))
# stat = response[,'status']
} else if(response_type == "counting") {
# time_start = response[,"start"]
# time_stop = response[,"stop"]
# stat = response[,"status"]
} else {
stop("response type is not supported")
}
# need to align data with baseline_hazard. done per individual/subject_id.
all_subject_ids <- data[,idx, drop = TRUE]
unique_subjects <- unique(all_subject_ids)
data_with_events <- data.frame(cbind(data[NULL, idx], X[NULL, ], data[NULL, Surv_vars]))
for (subject in unique_subjects) {
bool_select_rows <- all_subject_ids == subject
subject_data <- data[bool_select_rows, ]
subject_risk_scores = risk_score[bool_select_rows]
# take the start times
if(response_type == "right"){
# always length(subject_risk_scores) == 1  ?
subject_covariate_change_times <- rep(0, length(subject_risk_scores))
} else if(response_type == "counting") {
subject_covariate_change_times <- data[bool_select_rows, Surv_vars[1]]
}
# need to end up with a vector of hazards, and a vector of change points
hazards = double()
changes = double()
# subject_risk_scores and subject_covariate_change_times should be the same length
i_max = length(subject_risk_scores)
for (i in seq(i_max-1)) {
# identify hazards that occur in the interval covered by this risk score.
hazard_in_interval <- (t >= subject_covariate_change_times[i]) & (t < subject_covariate_change_times[i+1])
# multiply the risk score by each hazard in the interval
hazards = c(hazards, baseline_hazard[hazard_in_interval] * exp(subject_risk_scores[i]))
changes = c(changes, t[hazard_in_interval])
}
hazard_in_interval <- (t>=subject_covariate_change_times[i_max])
hazards = c(hazards, baseline_hazard[hazard_in_interval] * exp(subject_risk_scores[i_max]))
changes = c(changes, t[hazard_in_interval])
# now we have a set of changes and hazards for a particular subject.
# get a set of event times.
event_times = double()
current_event_time = origin
current_event_time_after_end_of_follow_up <- FALSE
# what is the end of follow up? Passed in by user.
if(event == "single"){
event_times <- msm::rpexp(n=1, rate = hazards, t = changes)
} else if(event == "recurrent"){
while (!current_event_time_after_end_of_follow_up) {
current_event_time <- msm::rpexp(n = 1, rate = hazards, t = changes, start = current_event_time)
event_times <- c(event_times, current_event_time)
current_event_time_after_end_of_follow_up <- current_event_time >= end_of_follow_up
}
# drop the last event time.
event_times <- head(event_times, -1)
}
# construct a new subject dataset that includes the event times.
# the current data
start_times <- subject_data[,Surv_vars[1]]
end_times   <- subject_data[,Surv_vars[2]]
status      <- subject_data[,Surv_vars[3]]
id          <- subject_data[,idx]
subject_X <- X[bool_select_rows, , drop = FALSE]
# new data
new_data_n <- length(event_times)
new_end_times <- event_times
new_start_times <- double(new_data_n)
new_subject_X <- matrix(,ncol = ncol(X), nrow = new_data_n)
colnames(new_subject_X) <- colnames(subject_X)
new_id <- rep(subject, new_data_n)
end_times <- c(end_times, new_end_times)
row_order <- order(end_times)
end_times <- end_times[row_order]
start_times <- c(origin, head(end_times, -1))
status <- c(status, rep(1, new_data_n))[row_order]
id <- c(id, new_id)[row_order]
subject_X <- rbind(subject_X, new_subject_X)[row_order, , drop = FALSE]
# take X from the obs after. only if row X is an event.
for (row in rev(seq(nrow(subject_X)))) {
if(status[row] == 1) {
subject_X[row, ] <- subject_X[row + 1,]
}
}
subject_data_with_events = data.frame(id, subject_X)
subject_data_with_events[Surv_vars[1]] <- start_times
subject_data_with_events[Surv_vars[2]] <- end_times
subject_data_with_events[Surv_vars[3]] <- status
# if it's a single event time, drop rows after that event?
if(event == "single"){
subject_data_with_events <- subject_data_with_events[end_times <= event_times, ]
}
data_with_events <- rbind.data.frame(data_with_events, subject_data_with_events)
}
# lets see where we're at at this point.
return(data_with_events)
}
t_follow_up_starts = 0
t_follow_up_ends = 10
t_change = runif(4, min = t_follow_up_starts, max = t_follow_up_ends/4) |> cumsum()
my_data = data.frame(t_start = c(0, t_change),
t_end = c(t_change, t_follow_up_ends),
X1 = rbinom(5, size = 1, prob = 0.5))
my_data$id = 1
my_data
draw_event_times(survival::Surv(t_start, t_end, stat) ~ X1, data = my_data, coefficients = c(X1 = 1.1),
baseline_hazard = 0.5, t=0 , origin = 0, id = id, event = "single", end_of_follow_up = 10)
draw_event_times(survival::Surv(t_end, stat) ~ X1, data = my_data, coefficients = c(X1 = 1.1),
baseline_hazard = 0.5, t=0 , origin = 0, id = id, event = "recurrent", end_of_follow_up = 10)
draw_event_times(survival::Surv(t_end, stat) ~ X1, data = my_data, coefficients = c(X1 = 1.1),
baseline_hazard = 0.1, t=0 , origin = 0, id = id, event = "recurrent", end_of_follow_up = 10)
draw_event_times(survival::Surv(t_end, stat) ~ X1, data = my_data, coefficients = c(X1 = 1.1),
baseline_hazard = 0.1, t=0 , origin = 0, id = id, event = "recurrent", end_of_follow_up = 10)
t_follow_up_starts = 0
t_follow_up_ends = 10
n_subject = 20
my_data = data.frame(id = rep(1:20, each = 5))
library(dplyr)
my_data <- my_data %>%
group_by(id) %>%
mutate(t_change = runif(n(), min = t_follow_up_starts, max = t_follow_up_ends/n()) |> cumsum()) %>%
mutate(t_start = lag(t_change, default = t_follow_up_starts),
t_end = lead(t_start, default = t_follow_up_ends),
X1 = rbinom(n(), size=1, prob = 0.5)) %>%
ungroup() %>% data.frame()
draw_event_times(survival::Surv(t_start, t_end, stat) ~ X1 + (1|id), data = my_data, coefficients = c(X1 = 1.1),
random_effect_variance = list(id = 1),
baseline_hazard = bh, t=bh_t , origin = 0, id = id, event = "single", end_of_follow_up = 10)
bh = c(1/(10:1))
bh_t = 0:9
draw_event_times(survival::Surv(t_start, t_end, stat) ~ X1, data = my_data, coefficients = c(X1 = 1.1),
baseline_hazard = bh, t=bh_t , origin = 0, id = id, event = "single", end_of_follow_up = 10)
draw_event_times(survival::Surv(t_end, stat) ~ X1, data = my_data, coefficients = c(X1 = 1.1),
baseline_hazard = bh, t=bh_t , origin = 0, id = id, event = "single", end_of_follow_up = 10)
draw_event_times(survival::Surv(t_start, t_end, stat) ~ X1, data = my_data, coefficients = c(X1 = 1.1),
baseline_hazard = bh, t=bh_t , origin = 0, id = id, event = "recurrent", end_of_follow_up = 10)
draw_event_times(survival::Surv(t_end, stat) ~ X1, data = my_data, coefficients = c(X1 = 1.1),
baseline_hazard = bh, t=bh_t , origin = 0, id = id, event = "recurrent", end_of_follow_up = 10)
draw_event_times(survival::Surv(t_start, t_end, stat) ~ X1 + (1|id), data = my_data, coefficients = c(X1 = 1.1),
random_effect_variance = list(id = 1),
baseline_hazard = bh, t=bh_t , origin = 0, id = id, event = "single", end_of_follow_up = 10)
param_combos <-
expand.grid(sample_size = c(500),
n_clusters_in_sample = 10:200,
n_clusters = 5000,
theta = c(0.0001, 0.5, 1, 2)) %>%
dplyr::mutate(cluster_size = sample_size/n_clusters_in_sample,
int_part = as.integer(cluster_size),
decimal_part = cluster_size - int_part) %>%
dplyr::arrange(theta, int_part, decimal_part) %>%
dplyr::group_by(theta, sample_size, int_part) %>%
dplyr::filter(dplyr::row_number() == 1) %>%
dplyr::select(n_clusters, theta, n_clusters_in_sample, cluster_size = int_part, sample_size) %>%
dplyr::ungroup() %>% data.frame()
nrow(param_combos)
log(4)
?estfun
methods(estfun)
methods(generics::estfun)
generics::estfun
hccm
??hccm
ids <- rep(1L:10L, each = 2)
ids
devtools::load_all(".")
C_draw_event_times(ids)
C_draw_event_times(ids)
ids <- rep(1L:10L, each = 2)
C_draw_event_times(ids)
devtools::load_all(".")
C_draw_event_times(ids)
ids <- rep(10L:1L, each = 2)
C_draw_event_times(ids)
devtools::load_all(".")
C_draw_event_times(ids)
devtools::load_all(".")
C_draw_event_times(ids)
