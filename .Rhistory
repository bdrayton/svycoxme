# fit a coxph model
# scaled weights
my_samp$rweight <- my_samp$weight/mean(my_samp$weight)
coxfit_rweighted <- coxme::coxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), data = my_samp, weights = rweight)
coxfit_weighted <- coxme::coxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), data = my_samp, weights = weight)
cbind(coef(coxfit_rweighted), coef(coxfit_weighted))
sv <- survey::as.svrepdesign(svydesign(~id, weights = ~weight, data = my_samp))
fit <- svycoxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), des = sv)
fit$coefficients
fit$variance
vcov(fit)
sandwich::sandwich(coxfit_rweighted)
vcov(coxfit_rweighted)
vcov(coxfit_weighted)
make_parts()
make_parts.coxme()
make_parts.coxme
View(coxfit_rweighted)
coxfit_rweighted$call
coxfit_rweighted$call[["weights"]]
class(coxfit_rweighted$call[["weights"]])
my_samp[coxfit_rweighted$call[["weights"]]]
str(coxfit_rweighted$call[["weights"]])
coxfit_rweighted$call[["weights"]][[1]]
as.character(coxfit_rweighted$call[["weights"]])
View(cluster_str)
sum(cluster_str$Freq)
devtools::load_all(".")
svycoxme_path <- "C:/Users/bdra011/OneDrive - The University of Auckland/Documents/PhD_local/svycoxme"
devtools::load_all(svycoxme_path)
svycoxme_path <- "C:/Users/bdra011/OneDrive - The University of Auckland/Documents/PhD_local/svycoxme"
devtools::load_all(svycoxme_path)
set.seed(949742)
cluster_str <- data.frame(table(Size = rpois(25000, 2) + 6)) |>
dplyr::filter(Freq >=10)
cluster_str_list <- split(cluster_str, seq(nrow(cluster_str)))
max_cluster_digits <- max(nchar(as.character(cluster_str$Size)))
max_cluster_freq_digits <- max(nchar(as.character(cluster_str$Freq)))
thetas <- c(0, 0.3, 0.5, 1, 2)
# set to 1600 for the real run.
nsims <- 10
# these are the parameter combinations to run on each pop
param_combos <- expand.grid(n_clusters = sum(cluster_str$Freq),
n_clusters_in_samp = c(50, 100, 200))
# repeat each combination of parameters nsims times
param_combos_nsims <- param_combos[rep(seq_len(nrow(param_combos)), nsims),]
# need rows as list
param_combos_list <- split(param_combos_nsims, f = seq_len(nrow(param_combos_nsims)))
# define one rep
one_rep <- function(specs){
# one cluster sample
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
my_samp <- my_samp[order(my_samp$stat_time)]
# the regular fit.
coxme_fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + (1|id), data = my_samp, weights = rweights)
# calculate ui and Hessian
parts <- make_parts(coxme_fit, my_samp, weights = my_samp$weights)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
my_des_rep <- as.svrepdesign(my_des)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
svycoxme_fit <- svycoxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), des = sv)
# calculate sandwich variance
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
sandwich_var  = diag(sandwich)[1:2],
svycoxme_var = diag(vcov(svycoxme_fit)),
coefs = coef(svycoxme_fit))
}
try_one_rep <- function(...){
stream <- .Random.seed
r <- try(one_rep(...))
attr(r, "stream") <- stream
r
}
# set to 20 for Ihaka
cores <- 5
parallel::detectCores()
cl <- parallel::makeCluster(cores)
# put objects in place that might be needed for the code
parallel::clusterExport(cl, c("one_rep", "try_one_rep"))
# Set a different seed on each member of the cluster (just in case)
# this could be set to avoid errors. currently one error.
parallel::clusterSetRNGStream(cl, iseed = 3528942)
parallel::clusterEvalQ(cl, {
# devtools::load_all(path = "/home/bdra011/svycoxme")
devtools::load_all(svycoxme_path)
# devtools::load_all("C:/Users/Bradley/Documents/PhD_local/svycoxme")
})
# put objects in place that might be needed for the code
parallel::clusterExport(cl, c("one_rep", "try_one_rep", "svycoxme_path"))
parallel::clusterEvalQ(cl, {
# devtools::load_all(path = "/home/bdra011/svycoxme")
devtools::load_all(svycoxme_path)
# devtools::load_all("C:/Users/Bradley/Documents/PhD_local/svycoxme")
})
run_one_pop <- function(theta){
# Build pop
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + X2 + (1 | M1),
dists = list(X1 = ~rnorm(n),
X2 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(X1 = 1, X2 = 1),
random_effect_variance = list(M1 = theta)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
parallel::clusterExport(cl, c("pop"))
fits <- parallel::parLapply(cl, param_combos_list, try_one_rep)
fits
}
all_fits <- lapply(thetas, run_one_pop)
test_fits <- run_one_pop(1)
debugonce(run_one_pop)
test_fits <- run_one_pop(1)
currentenv
debugonce(run_one_pop)
test_fits <- run_one_pop(1)
environment()
parent.env()
parent.frame()
run_one_pop <- function(theta){
# Build pop
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + X2 + (1 | M1),
dists = list(X1 = ~rnorm(n),
X2 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(X1 = 1, X2 = 1),
random_effect_variance = list(M1 = theta)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
parallel::clusterExport(cl, c("pop"), envir = parent.frame())
fits <- parallel::parLapply(cl, param_combos_list, try_one_rep)
fits
}
test_fits <- run_one_pop(1)
run_one_pop <- function(theta){
# Build pop
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + X2 + (1 | M1),
dists = list(X1 = ~rnorm(n),
X2 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(X1 = 1, X2 = 1),
random_effect_variance = list(M1 = theta)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
parallel::clusterExport(cl, c("pop"), envir = environment())
fits <- parallel::parLapply(cl, param_combos_list, try_one_rep)
fits
}
test_fits <- run_one_pop(1)
test_fits
#stop the cluster
parallel::stopCluster(cl)
one_rep(param_combos_list[[1]])
theta = 1
# Build pop
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + X2 + (1 | M1),
dists = list(X1 = ~rnorm(n),
X2 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(X1 = 1, X2 = 1),
random_effect_variance = list(M1 = theta)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
one_rep(param_combos_list[[1]])
debugonce(one_rep)
one_rep(param_combos_list[[1]])
my_samp$stat_time
# define one rep
one_rep <- function(specs){
# one cluster sample
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
my_samp <- my_samp[order(my_samp$stat_time), ]
# the regular fit.
coxme_fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + (1|id), data = my_samp, weights = rweights)
# calculate ui and Hessian
parts <- make_parts(coxme_fit, my_samp, weights = my_samp$weights)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
my_des_rep <- as.svrepdesign(my_des)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
svycoxme_fit <- svycoxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), des = sv)
# calculate sandwich variance
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
sandwich_var  = diag(sandwich)[1:2],
svycoxme_var = diag(vcov(svycoxme_fit)),
coefs = coef(svycoxme_fit))
}
try_one_rep <- function(...){
stream <- .Random.seed
r <- try(one_rep(...))
attr(r, "stream") <- stream
r
}
# set to 20 for Ihaka
cores <- 5
# set to 20 for Ihaka
cores <- 5
cl <- parallel::makeCluster(cores)
# put objects in place that might be needed for the code
parallel::clusterExport(cl, c("one_rep", "try_one_rep", "svycoxme_path"))
# Set a different seed on each member of the cluster (just in case)
# this could be set to avoid errors. currently one error.
parallel::clusterSetRNGStream(cl, iseed = 3528942)
parallel::clusterEvalQ(cl, {
# devtools::load_all(path = "/home/bdra011/svycoxme")
devtools::load_all(svycoxme_path)
# devtools::load_all("C:/Users/Bradley/Documents/PhD_local/svycoxme")
})
run_one_pop <- function(theta){
# Build pop
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + X2 + (1 | M1),
dists = list(X1 = ~rnorm(n),
X2 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(X1 = 1, X2 = 1),
random_effect_variance = list(M1 = theta)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
parallel::clusterExport(cl, c("pop"), envir = environment())
fits <- parallel::parLapply(cl, param_combos_list, try_one_rep)
fits
}
test_fits <- run_one_pop(1)
test_fits
# define one rep
one_rep <- function(specs){
# one cluster sample
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
my_samp <- my_samp[order(my_samp$stat_time), ]
# the regular fit.
coxme_fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + (1|id), data = my_samp, weights = rweights)
# calculate ui and Hessian
parts <- make_parts(coxme_fit, my_samp, weights = my_samp$weights)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
my_des_rep <- as.svrepdesign(my_des)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
svycoxme_fit <- svycoxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), des = my_des_rep)
# calculate sandwich variance
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
sandwich_var  = diag(sandwich)[1:2],
svycoxme_var = diag(vcov(svycoxme_fit)),
coefs = coef(svycoxme_fit))
}
test_fits <- run_one_pop(1)
table(sapply(test_fits, inherits, "try-error"))
test_fits[[1]]
# define one rep
one_rep <- function(specs){
# one cluster sample
samp_cluster_ids <- unique(pop$id)[sample.int(specs$n_clusters, specs$n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$prob <- (specs$n_clusters_in_samp/specs$n_clusters)
my_samp$weights <- my_samp$prob^-1
# rescale_weights
my_samp$rweights <- (1/my_samp$prob)/mean(1/my_samp$prob)
my_samp <- my_samp[order(my_samp$stat_time), ]
# the regular fit.
coxme_fit <- coxme::coxme(survival::Surv(stat_time, stat)~ X1 + X2 + (1|id), data = my_samp, weights = rweights)
# calculate ui and Hessian
parts <- make_parts(coxme_fit, my_samp, weights = my_samp$weights)
hessian <- calc_Di(parts)
ui <- calc_ui(parts)
# define design, add ui
my_des <- svydesign(~id, weights = ~weights, data = my_samp)
my_des_rep <- as.svrepdesign(my_des)
uvars <- paste("u", colnames(ui), sep = "_")
my_des$variables[uvars] <- as.matrix(ui)
svytotal_form1 <- formula(paste("~", paste(uvars, collapse = " + ")))
Nhat <- sum(weights(my_des))
svycoxme_fit <- svycoxme(survival::Surv(stat_time, stat) ~ X1 + X2 + (1 | id), des = my_des_rep)
# calculate sandwich variance
# division by Nhat needed?
meat_ui <- eval(bquote(vcov(svytotal(.(svytotal_form1), design = my_des))/Nhat))
my_bread <- solve(-hessian)
sandwich <- (my_bread %*% meat_ui %*% my_bread)/Nhat
list(
specs = specs,
sandwich_var  = diag(sandwich)[1:2],
svycoxme_var = diag(vcov(svycoxme_fit)),
coefs = coef(svycoxme_fit))
}
try_one_rep <- function(...){
stream <- .Random.seed
r <- try(one_rep(...))
attr(r, "stream") <- stream
r
}
# put objects in place that might be needed for the code
parallel::clusterExport(cl, c("one_rep", "try_one_rep", "svycoxme_path"))
run_one_pop <- function(theta){
# Build pop
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + X2 + (1 | M1),
dists = list(X1 = ~rnorm(n),
X2 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(X1 = 1, X2 = 1),
random_effect_variance = list(M1 = theta)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
parallel::clusterExport(cl, c("pop"), envir = environment())
fits <- parallel::parLapply(cl, param_combos_list, try_one_rep)
fits
}
test_fits <- run_one_pop(1)
table(sapply(test_fits, inherits, "try-error"))
test_fits
all_fits <- lapply(thetas, run_one_pop)
#stop the cluster
parallel::stopCluster(cl)
is.error <- sapply(fits, inherits, "try-error")
is.error <- sapply(all_fits, inherits, "try-error")
# none
table(is.error)
all_fits_unlist <- unlist(all_fits, recursive = FALSE)
is.error <- sapply(all_fits_unlist, inherits, "try-error")
# none
table(is.error)
all_fits_unlist <- unlist(all_fits, recursive = FALSE)
is.error <- sapply(all_fits_unlist, inherits, "try-error")
# none
table(is.error)
names(all_fits_unlist[[1]])
shape_res <- function(one_fit){
covars <- names(one_fit$coefs)
v1 <- diag(one_fit$sandwich_var)
v2 <- diag(one_fit$svycoxme_var)
data.frame(
method = rep(c("sandwich", "bootstrap"), each = 2),
covariate = rep(covars, 2),
coefs = rep(one_fit$coefs, 2),
variance = c(v1, v2),
lower = one_fit$coefs + qnorm(0.025) * sqrt(c(v1, v2)),
upper = one_fit$coefs + qnorm(0.975) * sqrt(c(v1, v2))
)
}
shape_res(fits[[1]])
shape_res(all_fits_unlist[[1]])
shape_res <- function(one_fit){
covars <- names(one_fit$coefs)
v1 <- one_fit$sandwich_var
v2 <- one_fit$svycoxme_var
data.frame(
method = rep(c("sandwich", "bootstrap"), each = 2),
covariate = rep(covars, 2),
coefs = rep(one_fit$coefs, 2),
variance = c(v1, v2),
lower = one_fit$coefs + qnorm(0.025) * sqrt(c(v1, v2)),
upper = one_fit$coefs + qnorm(0.975) * sqrt(c(v1, v2))
)
}
shape_res(all_fits_unlist[[1]])
fits_df <- lapply(fits[!is.error], shape_res)
fits_df <- lapply(all_fits_unlist[!is.error], shape_res)
df <- Reduce(rbind.data.frame, fits_df)
library(tidyverse)
df %>%
ggplot(aes(sqrt(variance))) +
facet_grid(rows = vars(covariate, method), scales = 'free') +
geom_density()
bias <- function(theta, true_theta){
sum(theta - true_theta)/length(theta)
}
df %>%
group_by(covariate, method) %>%
summarise(bias = bias(coefs, true_theta = 1))
EmpSE <- function(theta){
theta_bar = mean(theta)
sqrt( sum((theta-mean(theta))^2)/(length(theta)-1) )
}
df %>%
group_by(method, covariate) %>%
summarise(bias = bias(coefs, true_theta = 1),
EmpSE = EmpSE(coefs),
MeanSE = mean(sqrt(variance)),
diff = EmpSE - MeanSE)
# number of 'hits'
# about the same coverage. Will need to check for a range of parameters and sampling situations.
df %>%
group_by(method, covariate) %>%
mutate(hit = lower < 1 & upper > 1) %>%
summarise(mean(hit))
df %>%
arrange(lower) %>%
group_by(covariate) %>%
mutate(hit = lower < 1 & upper > 1,
index = row_number()) %>%
ggplot(aes(y = index, xmin = lower, xmax = upper, colour = hit)) +
geom_errorbarh(height = 0) +
facet_grid(rows = vars(covariate)) +
geom_vline(xintercept = 1)
devtools::load_all(".")
devtools::load_all(".")
Sys.info()
Sys.getenv()
svycoxme::svycoxme
devtools::load_all(".")
svycoxme::svycoxme
svycoxme
svycoxme.svyrep.design
devtools::load_all(".")
