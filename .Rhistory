pij <- UPmidzunopi2(rep(50/2500, 2500))[1, 2]
off_diag[1] == pij
off_diag[1] - pij
pi <- 50/2500
# make this way smaller.
cluster_str <- data.frame(table(Size = rpois(2500, 2) + 6)) |>
dplyr::filter(Freq >=10)
cluster_str_list <- split(cluster_str, seq(nrow(cluster_str)))
max_cluster_digits <- max(nchar(as.character(cluster_str$Size)))
max_cluster_freq_digits <- max(nchar(as.character(cluster_str$Freq)))
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + (1 | M1),
dists = list(X1 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(1),
random_effect_variance = list(M1 = 0)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
# weights
n_clusters <- dplyr::n_distinct(pop$id)
n_clusters_in_samp <- 50
# sample data
samp_cluster_ids <- unique(pop$id)[sample.int(n_clusters, n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$weight <- (n_clusters_in_samp/n_clusters)^-1
library(survey)
my_des <- svydesign(~id, weights = ~weight, data = my_samp)
svycox <- svycoxph(survival::Surv(stat_time, stat) ~ X1, design = my_des)
# target for variance
summary(svycox)
beta <- Matrix(coef(svycox))
model_frame <- model.frame(svycox)
BB <- function(formula, weight = NULL, data, beta){
model_frame <- model.frame(formula, data = data)
# first column (response) is actually a (masked) matrix with time and status.
response <- as.matrix(model_frame[ ,1])
time <- response[,"time"]
stat <- response[,"status"]
# sort data by time
stat <- stat[order(time)]
model_frame <- model_frame[order(time), ]
model_matrix <- model.matrix(formula, data = model_frame)
# calculate the weighted risk sets.
# get X terms
X <- model_matrix[,-1, drop = FALSE]
# this should fail if beta and X don't match dimensions
# I need these to be Matrix::Matrix
risk_score <- Matrix::Matrix(X %*% beta)
# weighted.
exp_risk_score <- weight * exp(risk_score)
rev_exp_risk_score <- exp_risk_score
rev_exp_risk_score@x <- rev(exp_risk_score@x)
# this is S0_hat in binder
at_risk <- Matrix::Matrix(rev(cumsum(rev_exp_risk_score)), ncol = 1)
# this is S1_hat
exp_risk_score_X <- exp_risk_score * X
at_risk_X <- fast_risk_sets(exp_risk_score_X)
at_risk_X_X <- fast_risk_sets(exp_risk_score_X * X)
list(stat = stat,
weight = weight,
S0 = at_risk,
S1 = at_risk_X,
weighted_exp_risk_score = exp_risk_score,
S2 = at_risk_X_X,
X = X)
}
coxfit <- survival::coxph(survival::Surv(stat_time, stat) ~ X1, data = my_samp,  weight = my_samp$weight)
coef(coxfit)
beta
parts <- BB(survival::Surv(stat_time, stat) ~ X1, data = my_samp, beta = coef(coxfit), weight = my_samp$weight)
# these are U_i s
U_i <- with(parts, {
weight * stat * (X - S1/S0)
})
N_hat <- sum(parts$weight)
N_hat
nrow(pop)
# another version, from lin
U_i_2 <- with(parts, {
stat * (X - S1/S0) - cumsum(stat * weighted_exp_risk_score / S0) * (X - S1/S0)/N_hat
})
my_samp_sorted <- sortAndIndex(my_samp, "stat_time")
my_des <- svydesign(~id, weights = ~weight, data = my_samp_sorted)
my_des$variables$U_i <- U_i_2[, 1]
vcov(svytotal(~U_i, design = my_des))
# linearly dependent, but one looks kind of standardised.
plot(U_i, U_i_2)
plot(density(U_i[,1]))
plot(density(U_i_2[,1]))
# dU
dU_parts <- with(parts, {
weight * stat * (S2 / S0 - (S1 * S1) / (S0 * S0))
})
D <- sum(dU_parts)/N_hat
D
U_i_2 %*% t(U_i_2)
seq_along(U_i_2)
nrow(U_i_2)
Vdf <- data.frame(i = rep(seq_along(U_i_2), each = nrow(U_i_2)),
j = rep(seq_along(U_i_2), nrow(U_i_2)),
Ui = rep(U_i_2, each = nrow(U_i_2)),
Uj = rep(U_i_2, nrow(U_i_2)))
Vdf <- Vdf |>
dplyr::mutate(pi = n_clusters_in_samp/n_clusters,
pj = pi,
pipj = pi * pj,
pij = UPmaxentropypi2(rep(pi, n_clusters))[1, 2])
n_clusters
n_clusters_in_samp
pij <- UPmaxentropypi2(rep(n_clusters_in_samp/n_clusters, n_clusters))[1, 2]
pij
Vdf <- Vdf |>
dplyr::mutate(pi = n_clusters_in_samp/n_clusters,
pj = pi,
pipj = pi * pj,
pij = pij)
Vdf <- Vdf |>
dplyr::mutate(pi = n_clusters_in_samp/n_clusters,
pj = pi,
pipj = pi * pj,
pij = pij,
pr = (pij - pipj) / (pij * pipj))
Vdf |>
dplyr::mutate(i_equal_j = i == j)
Vdf <- Vdf |>
dplyr::mutate(pi = n_clusters_in_samp/n_clusters,
pj = pi,
pipj = pi * pj,
pij = if_else(i == j, pi, pij),
pr = (pij - pipj) / (pij * pipj))
Vdf |>
dplyr::mutate(i_equal_j = i == j) |>
dplyr::group_by(i_equal_j) |>
dplyr::summarise(pr_mean = mean(pr_mean))
Vdf |>
dplyr::mutate(i_equal_j = i == j) |>
dplyr::group_by(i_equal_j) |>
dplyr::summarise(pr_mean = mean(pr))
Vdf |>
dplyr::mutate(V_parts = pr * U_i * U_j)
Vdf |>
dplyr::mutate(V_parts = pr * Ui * Uj)
Vdf <- Vdf |>
dplyr::mutate(V_parts = pr * Ui * Uj)
sum(Vdf$V_parts)
N_hat
sum(Vdf$V_parts)/N_hat
V_hat <- sum(Vdf$V_parts)/N_hat
D_hat <- sum(dU_parts)/N_hat
D_hat
solve(D_hat) %*% V_hat %*% solve(D_hat)
solve(D_hat) + solve(D_hat) %*% V_hat %*% solve(D_hat)
sqrt(solve(D_hat) + solve(D_hat) %*% V_hat %*% solve(D_hat))
solve(D_hat)
sqrt(solve(D_hat))
parts <- BB(survival::Surv(stat_time, stat) ~ X1, data = my_samp, beta = coef(coxfit), weight = my_samp$weight)
coxfit <- survival::coxph(survival::Surv(stat_time, stat) ~ X1, data = my_samp,  weight = my_samp$weight)
parts <- BB(survival::Surv(stat_time, stat) ~ X1, data = my_samp, beta = coef(coxfit), weight = my_samp$weight)
# these are U_i s
U_i <- with(parts, {
weight * stat * (X - S1/S0)
})
N_hat <- sum(parts$weight)
N_hat
# another version, from lin
U_i_2 <- with(parts, {
stat * (X - S1/S0) - cumsum(stat * weighted_exp_risk_score / S0) * (X - S1/S0)/N_hat
})
my_samp_sorted <- sortAndIndex(my_samp, "stat_time")
my_des <- svydesign(~id, weights = ~weight, data = my_samp_sorted)
U_i_2
U_i_2[, 1]
U_i_2
my_des$variables$U_i <- U_i_2[, 1]
vcov(svytotal(~U_i, design = my_des))
svytotal(~U_i, design = my_des)
svymean(~U_i, design = my_des)
# linearly dependent, but one looks kind of standardised.
plot(U_i, U_i_2)
plot(density(U_i[,1]))
plot(density(U_i_2[,1]))
plot(density(U_i[,1]))
plot(density(U_i_2[,1]))
svyfit <- svycoxph(survival::Surv(stat_time, stat) ~ X1, design = my_des)
resid(svyfit, type = "dfbeta")
U3 <- resid(svyfit, type = "dfbeta")
plot(U3, U_1_2)
plot(U3, U_i_2)
plot(U3, U_i_2, col = stat)
plot(U3, U_i_2, col = stat + 1)
plot(U3, U_i_2, col = parts$stat + 1)
table(parts$stat)
plot(U3, U_i_2, col = parts$stat + 1)
plot(density(U3))
my_des <- svydesign(~id, weights = ~weight, data = my_samp_sorted)
svyfit <- svycoxph(survival::Surv(stat_time, stat) ~ X1, design = my_des)
U3 <- resid(svyfit, type = "dfbeta")
plot(density(U3))
plot(U3, U_i_2, col = parts$stat + 1)
plot(U3, U_i, col = parts$stat + 1)
U4 <- dfbeta(coxfit)
U4 <- resid(coxfit, "dfbeta")
plot(U3, U4, col = parts$stat + 1)
plot(U3, U4[order(my_samp$stat_time)], col = parts$stat + 1)
sum(U4)
sum(U2)
sum(Ui)
sum(U_i)
vcov(svytotal(~U_i, design = my_des))
vcov(svytotal(~U_i, design = my_des))
my_des$variables$U_i <- U_i_2[, 1]
vcov(svytotal(~U_i, design = my_des))
V <- vcov(svytotal(~U_i, design = my_des))
V_svy <- vcov(svytotal(~U_i, design = my_des))
V_hat <- sum(Vdf$V_parts)/N_hat
V_svy
V_hat
sum(Vdf$V_parts)
solve(D_hat) + solve(D_hat) %*% V_svy %*% solve(D_hat)
solve(D_hat) + solve(D_hat) %*% (V_svy/N_hat) %*% solve(D_hat)
(V_svy/N_hat)
solve(D_hat) %*%
names(parts)
BB <- function(formula, weight = NULL, data, beta){
model_frame <- model.frame(formula, data = data)
# first column (response) is actually a (masked) matrix with time and status.
response <- as.matrix(model_frame[ ,1])
time <- response[,"time"]
stat <- response[,"status"]
# sort data by time
time_order <- order(time)
stat <- stat[time_order]
weight <- weight[time_order]
model_frame <- model_frame[time_order, ]
model_matrix <- model.matrix(formula, data = model_frame)
# calculate the weighted risk sets.
# get X terms
X <- model_matrix[,-1, drop = FALSE]
# this should fail if beta and X don't match dimensions
# I need these to be Matrix::Matrix
risk_score <- Matrix::Matrix(X %*% beta)
# weighted.
exp_risk_score <- weight * exp(risk_score)
rev_exp_risk_score <- exp_risk_score
rev_exp_risk_score@x <- rev(exp_risk_score@x)
# this is S0_hat in binder
at_risk <- Matrix::Matrix(rev(cumsum(rev_exp_risk_score)), ncol = 1)
# this is S1_hat
exp_risk_score_X <- exp_risk_score * X
at_risk_X <- fast_risk_sets(exp_risk_score_X)
at_risk_X_X <- fast_risk_sets(exp_risk_score_X * X)
list(stat = stat,
weight = weight,
S0 = at_risk,
S1 = at_risk_X,
exp_risk_score = exp(risk_score),
weighted_exp_risk_score = exp_risk_score,
S2 = at_risk_X_X,
X = X)
}
coxfit <- survival::coxph(survival::Surv(stat_time, stat) ~ X1, data = my_samp,  weight = my_samp$weight)
parts <- BB(survival::Surv(stat_time, stat) ~ X1, data = my_samp, beta = coef(coxfit), weight = my_samp$weight)
parts <- BB(survival::Surv(stat_time, stat) ~ X1, data = my_samp, beta = coef(coxfit), weight = my_samp$weight)
with(parts, {
S0 * X * exp_risk_score - S1 * exp_risk_score
})
# take the parts and calculate d2
dU <- function(parts){
t1 <- with(parts,{
-stat * (S2 / S0 - (S1 * S1) / (S0 * S0))
})
t2 <- with(parts, {
-cumsum(stat * weight * (S0 * X * exp_risk_score - S1 * exp_risk_score) / (S0 * S0)) * (X - S1/S0)/N_hat
})
t3 <- with(parts, {
- cumsum(stat * weighted_exp_risk_score / S0) * ( (S1 * S1) / (S0 * S0) - S2 / S0 )/N_hat
})
data.frame(t1, t2, t3)
}
dU(parts)
lapply(parts, class)
# take the parts and calculate d2
dU <- function(parts){
t1 <- with(parts,{
-stat * (S2 / S0 - (S1 * S1) / (S0 * S0))
})
t2 <- with(parts, {
-cumsum(stat * weight * (S0 * X * exp_risk_score - S1 * exp_risk_score) / (S0 * S0)) * (X - S1/S0)/N_hat
})
t3 <- with(parts, {
- cumsum(stat * weighted_exp_risk_score / S0) * ( (S1 * S1) / (S0 * S0) - S2 / S0 )/N_hat
})
list(t1, t2, t3)
}
dU(parts)
# take the parts and calculate d2
dU <- function(parts){
t1 <- with(parts,{
-stat * (S2 / S0 - (S1 * S1) / (S0 * S0))
})
t2 <- with(parts, {
-cumsum(stat * weight * (S0 * X * exp_risk_score - S1 * exp_risk_score) / (S0 * S0)) * (X - S1/S0)/N_hat
})
t3 <- with(parts, {
- cumsum(stat * weighted_exp_risk_score / S0) * ( (S1 * S1) / (S0 * S0) - S2 / S0 )/N_hat
})
t1 + t2 + t3
}
dU(parts)
sum(dU(parts))
BB <- function(formula, weight = NULL, data, beta){
model_frame <- model.frame(formula, data = data)
# first column (response) is actually a (masked) matrix with time and status.
response <- as.matrix(model_frame[ ,1])
time <- response[,"time"]
stat <- response[,"status"]
# sort data by time
time_order <- order(time)
stat <- stat[time_order]
weight <- weight[time_order]
model_frame <- model_frame[time_order, ]
model_matrix <- model.matrix(formula, data = model_frame)
# calculate the weighted risk sets.
# get X terms
X <- model_matrix[,-1, drop = FALSE]
# this should fail if beta and X don't match dimensions
# I need these to be Matrix::Matrix
risk_score <- Matrix::Matrix(X %*% beta)
# weighted.
exp_risk_score <- weight * exp(risk_score)
rev_exp_risk_score <- exp_risk_score
rev_exp_risk_score@x <- rev(exp_risk_score@x)
# this is S0_hat in binder
at_risk <- Matrix::Matrix(rev(cumsum(rev_exp_risk_score)), ncol = 1)
# this is S1_hat
exp_risk_score_X <- exp_risk_score * X
at_risk_X <- fast_risk_sets(exp_risk_score_X)
at_risk_X_X <- fast_risk_sets(exp_risk_score_X * X)
list(stat = stat,
weight = weight,
S0 = at_risk,
S1 = at_risk_X,
exp_risk_score = exp(risk_score),
weighted_exp_risk_score = exp_risk_score,
S2 = at_risk_X_X,
X = X)
}
coxfit <- survival::coxph(survival::Surv(stat_time, stat) ~ X1, data = my_samp,  weight = my_samp$weight)
# make this way smaller.
cluster_str <- data.frame(table(Size = rpois(2500, 2) + 6)) |>
dplyr::filter(Freq >=10)
cluster_str_list <- split(cluster_str, seq(nrow(cluster_str)))
max_cluster_digits <- max(nchar(as.character(cluster_str$Size)))
max_cluster_freq_digits <- max(nchar(as.character(cluster_str$Freq)))
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + (1 | M1),
dists = list(X1 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(1),
random_effect_variance = list(M1 = 0)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
devtools::load_all(".")
pop_list <- lapply(cluster_str_list, function(cluster_info){
k <- cluster_info$Freq
nk <- as.numeric(as.character(cluster_info$Size))
k_id <- formatC(k, width = max_cluster_freq_digits, flag = "0")
nk_id <- formatC(nk, width = max_cluster_digits, flag = "0")
the_data <- one_dataset(~X1 + (1 | M1),
dists = list(X1 = ~rnorm(n),
M1 = ~rep(1:k, each = nk),
error = ~rexp(n, 10),
stat = ~sample(rep(c(0, 1), round(n * c(0.2, 0.8))), n)),
dist_args = list(k = k, nk = nk,
n = k * nk),
coefficients = c(1),
random_effect_variance = list(M1 = 0)
)
dplyr::mutate(the_data, id = paste(nk_id,k_id, M1, sep = "_" ))
})
pop <- Reduce(rbind.data.frame, pop_list)
# weights
n_clusters <- dplyr::n_distinct(pop$id)
n_clusters_in_samp <- 50
# sample data
samp_cluster_ids <- unique(pop$id)[sample.int(n_clusters, n_clusters_in_samp)]
my_samp <- pop[pop$id %in% samp_cluster_ids, ]
my_samp$weight <- (n_clusters_in_samp/n_clusters)^-1
library(survey)
my_des <- svydesign(~id, weights = ~weight, data = my_samp)
svycox <- svycoxph(survival::Surv(stat_time, stat) ~ X1, design = my_des)
# target for variance
summary(svycox)
beta <- Matrix(coef(svycox))
beta
model_frame <- model.frame(svycox)
# sort by fail time
fail_time <- Matrix(as.matrix(model_frame[,1])[,"time"], ncol = 1)
model_frame <- model_frame[order(fail_time), ]
X <- model_frame[, "X1", drop = FALSE] |> as.matrix()
stat <- Matrix(as.matrix(model_frame[,1])[,"status"], ncol = 1)
weight <- my_samp$weight[order(fail_time)]
risk_score <- X %*% beta
exp_risk_score <- weight * exp(risk_score)
dim(risk_score)
#Q0_beta = Q0_b
rev_exp_risk_score <- exp_risk_score
rev_exp_risk_score@x <- rev(exp_risk_score@x)
at_risk <- Matrix::Matrix(rev(cumsum(rev_exp_risk_score)), ncol = 1)
Q0_beta <- at_risk
# Q1_beta
exp_risk_score_X <- exp_risk_score * X
at_risk_X <- fast_risk_sets(exp_risk_score_X)
Q1_beta <- at_risk_X
dim(Q0_beta)
dim(Q1_beta)
A <- X - Q1_beta / Q0_beta
N_hat <- sum(weights(my_des))
# the first part of this middle term is a cumulative hazard of sorts. the second is gradient.
B <- cumsum((stat * exp_risk_score) / Q0_beta)/N_hat
U_i <- stat * A - B * A
my_des$variables$U_i <- U_i@x
svytotal(~U_i, design = my_des)
var_est <- vcov(svytotal(~U_i, design = my_des))
sqrt(var_est)
BB <- function(formula, weight = NULL, data, beta){
model_frame <- model.frame(formula, data = data)
# first column (response) is actually a (masked) matrix with time and status.
response <- as.matrix(model_frame[ ,1])
time <- response[,"time"]
stat <- response[,"status"]
# sort data by time
time_order <- order(time)
stat <- stat[time_order]
weight <- weight[time_order]
model_frame <- model_frame[time_order, ]
model_matrix <- model.matrix(formula, data = model_frame)
# calculate the weighted risk sets.
# get X terms
X <- model_matrix[,-1, drop = FALSE]
# this should fail if beta and X don't match dimensions
# I need these to be Matrix::Matrix
risk_score <- Matrix::Matrix(X %*% beta)
# weighted.
exp_risk_score <- weight * exp(risk_score)
rev_exp_risk_score <- exp_risk_score
rev_exp_risk_score@x <- rev(exp_risk_score@x)
# this is S0_hat in binder
at_risk <- Matrix::Matrix(rev(cumsum(rev_exp_risk_score)), ncol = 1)
# this is S1_hat
exp_risk_score_X <- exp_risk_score * X
at_risk_X <- fast_risk_sets(exp_risk_score_X)
at_risk_X_X <- fast_risk_sets(exp_risk_score_X * X)
list(stat = stat,
weight = weight,
S0 = at_risk,
S1 = at_risk_X,
exp_risk_score = exp(risk_score),
weighted_exp_risk_score = exp_risk_score,
S2 = at_risk_X_X,
X = X)
}
coxfit <- survival::coxph(survival::Surv(stat_time, stat) ~ X1, data = my_samp,  weight = my_samp$weight)
U4 <- resid(coxfit, "dfbeta")
parts <- BB(survival::Surv(stat_time, stat) ~ X1, data = my_samp, beta = coef(coxfit), weight = my_samp$weight)
# these are U_i s from binder
U_i <- with(parts, {
weight * stat * (X - S1/S0)
})
N_hat <- sum(parts$weight)
# another version, from lin
U_i_2 <- with(parts, {
stat * (X - S1/S0) - cumsum(stat * weighted_exp_risk_score / S0) * (X - S1/S0)/N_hat
})
my_samp_sorted <- sortAndIndex(my_samp, "stat_time")
my_des <- svydesign(~id, weights = ~weight, data = my_samp_sorted)
my_des$variables$U_i <- U_i_2[, 1]
V_svy <- vcov(svytotal(~U_i, design = my_des))
svymean(~U_i, design = my_des)
svytotal(~U_i, design = my_des)
# linearly dependent, but one looks kind of standardised.
plot(U_i, U_i_2)
svyfit <- svycoxph(survival::Surv(stat_time, stat) ~ X1, design = my_des)
U3 <- resid(svyfit, type = "dfbeta")
plot(density(U3))
plot(U3, U_i, col = parts$stat + 1)
plot(U3, U_i_2, col = parts$stat + 1)
plot(U3, U_i, col = parts$stat + 1, ylab = "dfbeta", xlab = "Binder U_i")
devtools::load_all(".")
devtools::load_all(".")
install.packages("roxygen2")
devtools::load_all(".")
svycoxme::calc_ui
